{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.10128633647320977,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0020257267294641955,
      "grad_norm": 2.4405038356781006,
      "learning_rate": 4.998075559607009e-05,
      "loss": 0.5615,
      "step": 20
    },
    {
      "epoch": 0.004051453458928391,
      "grad_norm": 1.4659157991409302,
      "learning_rate": 4.996049832877545e-05,
      "loss": 0.3374,
      "step": 40
    },
    {
      "epoch": 0.006077180188392586,
      "grad_norm": 1.5483160018920898,
      "learning_rate": 4.994024106148081e-05,
      "loss": 0.2433,
      "step": 60
    },
    {
      "epoch": 0.008102906917856782,
      "grad_norm": 2.1053307056427,
      "learning_rate": 4.9919983794186165e-05,
      "loss": 0.2178,
      "step": 80
    },
    {
      "epoch": 0.010128633647320976,
      "grad_norm": 0.9805480241775513,
      "learning_rate": 4.989972652689153e-05,
      "loss": 0.2048,
      "step": 100
    },
    {
      "epoch": 0.012154360376785172,
      "grad_norm": 2.8173420429229736,
      "learning_rate": 4.987946925959689e-05,
      "loss": 0.1792,
      "step": 120
    },
    {
      "epoch": 0.014180087106249366,
      "grad_norm": 3.2427754402160645,
      "learning_rate": 4.985921199230224e-05,
      "loss": 0.1567,
      "step": 140
    },
    {
      "epoch": 0.016205813835713564,
      "grad_norm": 1.0643627643585205,
      "learning_rate": 4.9838954725007595e-05,
      "loss": 0.1468,
      "step": 160
    },
    {
      "epoch": 0.018231540565177756,
      "grad_norm": 2.5849173069000244,
      "learning_rate": 4.981971032107769e-05,
      "loss": 0.1942,
      "step": 180
    },
    {
      "epoch": 0.020257267294641952,
      "grad_norm": 13.793347358703613,
      "learning_rate": 4.979945305378305e-05,
      "loss": 0.1739,
      "step": 200
    },
    {
      "epoch": 0.022282994024106148,
      "grad_norm": 1.154039978981018,
      "learning_rate": 4.97791957864884e-05,
      "loss": 0.1475,
      "step": 220
    },
    {
      "epoch": 0.024308720753570344,
      "grad_norm": 1.3792349100112915,
      "learning_rate": 4.9758938519193764e-05,
      "loss": 0.1279,
      "step": 240
    },
    {
      "epoch": 0.02633444748303454,
      "grad_norm": 1.2435647249221802,
      "learning_rate": 4.973868125189912e-05,
      "loss": 0.1234,
      "step": 260
    },
    {
      "epoch": 0.028360174212498732,
      "grad_norm": 0.7834601402282715,
      "learning_rate": 4.971842398460448e-05,
      "loss": 0.1422,
      "step": 280
    },
    {
      "epoch": 0.030385900941962928,
      "grad_norm": 0.8932020664215088,
      "learning_rate": 4.9698166717309836e-05,
      "loss": 0.1231,
      "step": 300
    },
    {
      "epoch": 0.03241162767142713,
      "grad_norm": 1.0319157838821411,
      "learning_rate": 4.96779094500152e-05,
      "loss": 0.1448,
      "step": 320
    },
    {
      "epoch": 0.03443735440089132,
      "grad_norm": 0.9127151966094971,
      "learning_rate": 4.965765218272056e-05,
      "loss": 0.1259,
      "step": 340
    },
    {
      "epoch": 0.03646308113035551,
      "grad_norm": 1.1230705976486206,
      "learning_rate": 4.963739491542591e-05,
      "loss": 0.1174,
      "step": 360
    },
    {
      "epoch": 0.03848880785981971,
      "grad_norm": 4.197830677032471,
      "learning_rate": 4.9617137648131265e-05,
      "loss": 0.1239,
      "step": 380
    },
    {
      "epoch": 0.040514534589283904,
      "grad_norm": 0.9139384627342224,
      "learning_rate": 4.959688038083663e-05,
      "loss": 0.1511,
      "step": 400
    },
    {
      "epoch": 0.0425402613187481,
      "grad_norm": 1.3449727296829224,
      "learning_rate": 4.957662311354199e-05,
      "loss": 0.1322,
      "step": 420
    },
    {
      "epoch": 0.044565988048212296,
      "grad_norm": 3.993757724761963,
      "learning_rate": 4.9556365846247344e-05,
      "loss": 0.1058,
      "step": 440
    },
    {
      "epoch": 0.04659171477767649,
      "grad_norm": 4.853125095367432,
      "learning_rate": 4.95361085789527e-05,
      "loss": 0.1022,
      "step": 460
    },
    {
      "epoch": 0.04861744150714069,
      "grad_norm": 1.7318204641342163,
      "learning_rate": 4.9515851311658066e-05,
      "loss": 0.126,
      "step": 480
    },
    {
      "epoch": 0.050643168236604884,
      "grad_norm": 2.970012664794922,
      "learning_rate": 4.9495594044363416e-05,
      "loss": 0.1009,
      "step": 500
    },
    {
      "epoch": 0.05266889496606908,
      "grad_norm": 2.0667383670806885,
      "learning_rate": 4.9475336777068773e-05,
      "loss": 0.1033,
      "step": 520
    },
    {
      "epoch": 0.054694621695533276,
      "grad_norm": 1.1282299757003784,
      "learning_rate": 4.945507950977413e-05,
      "loss": 0.0934,
      "step": 540
    },
    {
      "epoch": 0.056720348424997465,
      "grad_norm": 2.0177979469299316,
      "learning_rate": 4.943482224247949e-05,
      "loss": 0.1238,
      "step": 560
    },
    {
      "epoch": 0.05874607515446166,
      "grad_norm": 1.2376540899276733,
      "learning_rate": 4.941456497518485e-05,
      "loss": 0.0871,
      "step": 580
    },
    {
      "epoch": 0.060771801883925856,
      "grad_norm": 2.9011895656585693,
      "learning_rate": 4.939430770789021e-05,
      "loss": 0.1128,
      "step": 600
    },
    {
      "epoch": 0.06279752861339005,
      "grad_norm": 1.1684095859527588,
      "learning_rate": 4.937405044059557e-05,
      "loss": 0.1189,
      "step": 620
    },
    {
      "epoch": 0.06482325534285426,
      "grad_norm": 0.638354480266571,
      "learning_rate": 4.9353793173300924e-05,
      "loss": 0.1053,
      "step": 640
    },
    {
      "epoch": 0.06684898207231844,
      "grad_norm": 2.9932680130004883,
      "learning_rate": 4.933353590600628e-05,
      "loss": 0.085,
      "step": 660
    },
    {
      "epoch": 0.06887470880178263,
      "grad_norm": 8.7505464553833,
      "learning_rate": 4.931327863871164e-05,
      "loss": 0.1089,
      "step": 680
    },
    {
      "epoch": 0.07090043553124684,
      "grad_norm": 2.4463045597076416,
      "learning_rate": 4.9293021371416996e-05,
      "loss": 0.0881,
      "step": 700
    },
    {
      "epoch": 0.07292616226071102,
      "grad_norm": 2.3883886337280273,
      "learning_rate": 4.9272764104122354e-05,
      "loss": 0.1098,
      "step": 720
    },
    {
      "epoch": 0.07495188899017523,
      "grad_norm": 1.602027177810669,
      "learning_rate": 4.925250683682772e-05,
      "loss": 0.1225,
      "step": 740
    },
    {
      "epoch": 0.07697761571963942,
      "grad_norm": 3.593160390853882,
      "learning_rate": 4.9232249569533075e-05,
      "loss": 0.1089,
      "step": 760
    },
    {
      "epoch": 0.07900334244910362,
      "grad_norm": 0.7113755345344543,
      "learning_rate": 4.921199230223843e-05,
      "loss": 0.0966,
      "step": 780
    },
    {
      "epoch": 0.08102906917856781,
      "grad_norm": 3.9807815551757812,
      "learning_rate": 4.919173503494379e-05,
      "loss": 0.1001,
      "step": 800
    },
    {
      "epoch": 0.08305479590803201,
      "grad_norm": 1.8223150968551636,
      "learning_rate": 4.917147776764915e-05,
      "loss": 0.1339,
      "step": 820
    },
    {
      "epoch": 0.0850805226374962,
      "grad_norm": 2.0231804847717285,
      "learning_rate": 4.9151220500354504e-05,
      "loss": 0.1171,
      "step": 840
    },
    {
      "epoch": 0.0871062493669604,
      "grad_norm": 2.085484027862549,
      "learning_rate": 4.913096323305986e-05,
      "loss": 0.1049,
      "step": 860
    },
    {
      "epoch": 0.08913197609642459,
      "grad_norm": 2.450080633163452,
      "learning_rate": 4.911070596576522e-05,
      "loss": 0.0904,
      "step": 880
    },
    {
      "epoch": 0.09115770282588878,
      "grad_norm": 3.7373743057250977,
      "learning_rate": 4.909044869847058e-05,
      "loss": 0.1062,
      "step": 900
    },
    {
      "epoch": 0.09318342955535298,
      "grad_norm": 0.4202941656112671,
      "learning_rate": 4.907019143117594e-05,
      "loss": 0.1187,
      "step": 920
    },
    {
      "epoch": 0.09520915628481717,
      "grad_norm": 1.1584241390228271,
      "learning_rate": 4.90499341638813e-05,
      "loss": 0.1048,
      "step": 940
    },
    {
      "epoch": 0.09723488301428138,
      "grad_norm": 5.440037250518799,
      "learning_rate": 4.902967689658665e-05,
      "loss": 0.1098,
      "step": 960
    },
    {
      "epoch": 0.09926060974374556,
      "grad_norm": 4.4612321853637695,
      "learning_rate": 4.9009419629292006e-05,
      "loss": 0.1114,
      "step": 980
    },
    {
      "epoch": 0.10128633647320977,
      "grad_norm": 0.742353618144989,
      "learning_rate": 4.898916236199737e-05,
      "loss": 0.0886,
      "step": 1000
    }
  ],
  "logging_steps": 20,
  "max_steps": 49365,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.0111822086144e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
