{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.5182186234817814,
  "eval_steps": 500,
  "global_step": 1500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.020242914979757085,
      "grad_norm": 2.60353684425354,
      "learning_rate": 4.980769230769231e-05,
      "loss": 0.5543,
      "step": 20
    },
    {
      "epoch": 0.04048582995951417,
      "grad_norm": 1.4951989650726318,
      "learning_rate": 4.960526315789474e-05,
      "loss": 0.3538,
      "step": 40
    },
    {
      "epoch": 0.06072874493927125,
      "grad_norm": 1.2178782224655151,
      "learning_rate": 4.940283400809717e-05,
      "loss": 0.2834,
      "step": 60
    },
    {
      "epoch": 0.08097165991902834,
      "grad_norm": 1.408525824546814,
      "learning_rate": 4.92004048582996e-05,
      "loss": 0.2507,
      "step": 80
    },
    {
      "epoch": 0.10121457489878542,
      "grad_norm": 2.4710991382598877,
      "learning_rate": 4.899797570850202e-05,
      "loss": 0.232,
      "step": 100
    },
    {
      "epoch": 0.1214574898785425,
      "grad_norm": 1.517261028289795,
      "learning_rate": 4.879554655870446e-05,
      "loss": 0.1583,
      "step": 120
    },
    {
      "epoch": 0.1417004048582996,
      "grad_norm": 2.8705952167510986,
      "learning_rate": 4.8603238866396764e-05,
      "loss": 0.2336,
      "step": 140
    },
    {
      "epoch": 0.16194331983805668,
      "grad_norm": 2.681584358215332,
      "learning_rate": 4.8400809716599195e-05,
      "loss": 0.1664,
      "step": 160
    },
    {
      "epoch": 0.18218623481781376,
      "grad_norm": 1.6810041666030884,
      "learning_rate": 4.819838056680162e-05,
      "loss": 0.2291,
      "step": 180
    },
    {
      "epoch": 0.20242914979757085,
      "grad_norm": 2.6532223224639893,
      "learning_rate": 4.7995951417004056e-05,
      "loss": 0.1705,
      "step": 200
    },
    {
      "epoch": 0.22267206477732793,
      "grad_norm": 2.7997703552246094,
      "learning_rate": 4.779352226720648e-05,
      "loss": 0.151,
      "step": 220
    },
    {
      "epoch": 0.242914979757085,
      "grad_norm": 4.134150981903076,
      "learning_rate": 4.759109311740891e-05,
      "loss": 0.1737,
      "step": 240
    },
    {
      "epoch": 0.2631578947368421,
      "grad_norm": 6.276228427886963,
      "learning_rate": 4.738866396761134e-05,
      "loss": 0.1654,
      "step": 260
    },
    {
      "epoch": 0.2834008097165992,
      "grad_norm": 1.7194103002548218,
      "learning_rate": 4.7186234817813765e-05,
      "loss": 0.1279,
      "step": 280
    },
    {
      "epoch": 0.30364372469635625,
      "grad_norm": 3.241950511932373,
      "learning_rate": 4.6983805668016196e-05,
      "loss": 0.1641,
      "step": 300
    },
    {
      "epoch": 0.32388663967611336,
      "grad_norm": 9.388757705688477,
      "learning_rate": 4.6781376518218626e-05,
      "loss": 0.2066,
      "step": 320
    },
    {
      "epoch": 0.3441295546558704,
      "grad_norm": 0.6280366778373718,
      "learning_rate": 4.658906882591093e-05,
      "loss": 0.1364,
      "step": 340
    },
    {
      "epoch": 0.3643724696356275,
      "grad_norm": 4.365753650665283,
      "learning_rate": 4.638663967611336e-05,
      "loss": 0.1371,
      "step": 360
    },
    {
      "epoch": 0.38461538461538464,
      "grad_norm": 8.496685028076172,
      "learning_rate": 4.618421052631579e-05,
      "loss": 0.1191,
      "step": 380
    },
    {
      "epoch": 0.4048582995951417,
      "grad_norm": 8.699529647827148,
      "learning_rate": 4.5981781376518216e-05,
      "loss": 0.1495,
      "step": 400
    },
    {
      "epoch": 0.4251012145748988,
      "grad_norm": 5.345395565032959,
      "learning_rate": 4.577935222672065e-05,
      "loss": 0.1394,
      "step": 420
    },
    {
      "epoch": 0.44534412955465585,
      "grad_norm": 4.354844570159912,
      "learning_rate": 4.557692307692308e-05,
      "loss": 0.1314,
      "step": 440
    },
    {
      "epoch": 0.46558704453441296,
      "grad_norm": 7.832252025604248,
      "learning_rate": 4.537449392712551e-05,
      "loss": 0.1813,
      "step": 460
    },
    {
      "epoch": 0.48582995951417,
      "grad_norm": 0.4733159840106964,
      "learning_rate": 4.517206477732794e-05,
      "loss": 0.1474,
      "step": 480
    },
    {
      "epoch": 0.5060728744939271,
      "grad_norm": 4.4916768074035645,
      "learning_rate": 4.496963562753036e-05,
      "loss": 0.1178,
      "step": 500
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 6.250394344329834,
      "learning_rate": 4.47672064777328e-05,
      "loss": 0.1279,
      "step": 520
    },
    {
      "epoch": 0.5465587044534413,
      "grad_norm": 1.0069736242294312,
      "learning_rate": 4.4564777327935224e-05,
      "loss": 0.127,
      "step": 540
    },
    {
      "epoch": 0.5668016194331984,
      "grad_norm": 2.2202513217926025,
      "learning_rate": 4.4362348178137654e-05,
      "loss": 0.1244,
      "step": 560
    },
    {
      "epoch": 0.5870445344129555,
      "grad_norm": 2.029829978942871,
      "learning_rate": 4.4159919028340085e-05,
      "loss": 0.1545,
      "step": 580
    },
    {
      "epoch": 0.6072874493927125,
      "grad_norm": 1.6138578653335571,
      "learning_rate": 4.3957489878542516e-05,
      "loss": 0.1674,
      "step": 600
    },
    {
      "epoch": 0.6275303643724697,
      "grad_norm": 3.7324604988098145,
      "learning_rate": 4.375506072874494e-05,
      "loss": 0.1436,
      "step": 620
    },
    {
      "epoch": 0.6477732793522267,
      "grad_norm": 4.236327648162842,
      "learning_rate": 4.356275303643725e-05,
      "loss": 0.1317,
      "step": 640
    },
    {
      "epoch": 0.6680161943319838,
      "grad_norm": 11.883174896240234,
      "learning_rate": 4.3360323886639674e-05,
      "loss": 0.1609,
      "step": 660
    },
    {
      "epoch": 0.6882591093117408,
      "grad_norm": 1.322102665901184,
      "learning_rate": 4.3157894736842105e-05,
      "loss": 0.1057,
      "step": 680
    },
    {
      "epoch": 0.708502024291498,
      "grad_norm": 3.9290645122528076,
      "learning_rate": 4.2955465587044536e-05,
      "loss": 0.1542,
      "step": 700
    },
    {
      "epoch": 0.728744939271255,
      "grad_norm": 2.389382839202881,
      "learning_rate": 4.2753036437246966e-05,
      "loss": 0.1145,
      "step": 720
    },
    {
      "epoch": 0.7489878542510121,
      "grad_norm": 0.7864636778831482,
      "learning_rate": 4.25506072874494e-05,
      "loss": 0.0963,
      "step": 740
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 1.3286188840866089,
      "learning_rate": 4.234817813765182e-05,
      "loss": 0.1284,
      "step": 760
    },
    {
      "epoch": 0.7894736842105263,
      "grad_norm": 7.57919454574585,
      "learning_rate": 4.214574898785426e-05,
      "loss": 0.1308,
      "step": 780
    },
    {
      "epoch": 0.8097165991902834,
      "grad_norm": 5.662615776062012,
      "learning_rate": 4.194331983805668e-05,
      "loss": 0.1644,
      "step": 800
    },
    {
      "epoch": 0.8299595141700404,
      "grad_norm": 6.5239410400390625,
      "learning_rate": 4.174089068825911e-05,
      "loss": 0.1093,
      "step": 820
    },
    {
      "epoch": 0.8502024291497976,
      "grad_norm": 0.7537091970443726,
      "learning_rate": 4.1538461538461544e-05,
      "loss": 0.1293,
      "step": 840
    },
    {
      "epoch": 0.8704453441295547,
      "grad_norm": 1.4398534297943115,
      "learning_rate": 4.133603238866397e-05,
      "loss": 0.1366,
      "step": 860
    },
    {
      "epoch": 0.8906882591093117,
      "grad_norm": 1.0573694705963135,
      "learning_rate": 4.11336032388664e-05,
      "loss": 0.1181,
      "step": 880
    },
    {
      "epoch": 0.9109311740890689,
      "grad_norm": 1.6042877435684204,
      "learning_rate": 4.093117408906883e-05,
      "loss": 0.1556,
      "step": 900
    },
    {
      "epoch": 0.9311740890688259,
      "grad_norm": 1.6729271411895752,
      "learning_rate": 4.072874493927126e-05,
      "loss": 0.0979,
      "step": 920
    },
    {
      "epoch": 0.951417004048583,
      "grad_norm": 1.523969054222107,
      "learning_rate": 4.0526315789473684e-05,
      "loss": 0.1277,
      "step": 940
    },
    {
      "epoch": 0.97165991902834,
      "grad_norm": 5.040785312652588,
      "learning_rate": 4.0323886639676114e-05,
      "loss": 0.1036,
      "step": 960
    },
    {
      "epoch": 0.9919028340080972,
      "grad_norm": 2.866434097290039,
      "learning_rate": 4.0121457489878545e-05,
      "loss": 0.1359,
      "step": 980
    },
    {
      "epoch": 1.0121457489878543,
      "grad_norm": 3.0122830867767334,
      "learning_rate": 3.991902834008097e-05,
      "loss": 0.1335,
      "step": 1000
    },
    {
      "epoch": 1.0323886639676114,
      "grad_norm": 0.7991473078727722,
      "learning_rate": 3.9716599190283406e-05,
      "loss": 0.1215,
      "step": 1020
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 1.5124045610427856,
      "learning_rate": 3.951417004048583e-05,
      "loss": 0.0833,
      "step": 1040
    },
    {
      "epoch": 1.0728744939271255,
      "grad_norm": 0.8686792254447937,
      "learning_rate": 3.931174089068826e-05,
      "loss": 0.0868,
      "step": 1060
    },
    {
      "epoch": 1.0931174089068827,
      "grad_norm": 0.6204802989959717,
      "learning_rate": 3.910931174089069e-05,
      "loss": 0.1123,
      "step": 1080
    },
    {
      "epoch": 1.1133603238866396,
      "grad_norm": 1.5977180004119873,
      "learning_rate": 3.890688259109312e-05,
      "loss": 0.0891,
      "step": 1100
    },
    {
      "epoch": 1.1336032388663968,
      "grad_norm": 1.9436721801757812,
      "learning_rate": 3.8704453441295546e-05,
      "loss": 0.0985,
      "step": 1120
    },
    {
      "epoch": 1.1538461538461537,
      "grad_norm": 1.1701987981796265,
      "learning_rate": 3.850202429149798e-05,
      "loss": 0.1505,
      "step": 1140
    },
    {
      "epoch": 1.174089068825911,
      "grad_norm": 17.12029266357422,
      "learning_rate": 3.829959514170041e-05,
      "loss": 0.1285,
      "step": 1160
    },
    {
      "epoch": 1.194331983805668,
      "grad_norm": 8.780117988586426,
      "learning_rate": 3.809716599190283e-05,
      "loss": 0.1086,
      "step": 1180
    },
    {
      "epoch": 1.214574898785425,
      "grad_norm": 0.9133884310722351,
      "learning_rate": 3.789473684210527e-05,
      "loss": 0.1054,
      "step": 1200
    },
    {
      "epoch": 1.2348178137651822,
      "grad_norm": 0.4866701662540436,
      "learning_rate": 3.769230769230769e-05,
      "loss": 0.0641,
      "step": 1220
    },
    {
      "epoch": 1.2550607287449393,
      "grad_norm": 0.8039166927337646,
      "learning_rate": 3.748987854251012e-05,
      "loss": 0.1268,
      "step": 1240
    },
    {
      "epoch": 1.2753036437246963,
      "grad_norm": 5.949751377105713,
      "learning_rate": 3.7287449392712554e-05,
      "loss": 0.1019,
      "step": 1260
    },
    {
      "epoch": 1.2955465587044535,
      "grad_norm": 0.2436349242925644,
      "learning_rate": 3.708502024291498e-05,
      "loss": 0.1134,
      "step": 1280
    },
    {
      "epoch": 1.3157894736842106,
      "grad_norm": 0.3876831531524658,
      "learning_rate": 3.688259109311741e-05,
      "loss": 0.0828,
      "step": 1300
    },
    {
      "epoch": 1.3360323886639676,
      "grad_norm": 1.0606331825256348,
      "learning_rate": 3.668016194331984e-05,
      "loss": 0.0899,
      "step": 1320
    },
    {
      "epoch": 1.3562753036437247,
      "grad_norm": 1.8161728382110596,
      "learning_rate": 3.647773279352227e-05,
      "loss": 0.1133,
      "step": 1340
    },
    {
      "epoch": 1.376518218623482,
      "grad_norm": 2.027841329574585,
      "learning_rate": 3.62753036437247e-05,
      "loss": 0.0958,
      "step": 1360
    },
    {
      "epoch": 1.3967611336032388,
      "grad_norm": 2.5625786781311035,
      "learning_rate": 3.607287449392713e-05,
      "loss": 0.0848,
      "step": 1380
    },
    {
      "epoch": 1.417004048582996,
      "grad_norm": 1.9966802597045898,
      "learning_rate": 3.5870445344129555e-05,
      "loss": 0.086,
      "step": 1400
    },
    {
      "epoch": 1.4372469635627532,
      "grad_norm": 2.6053574085235596,
      "learning_rate": 3.5668016194331986e-05,
      "loss": 0.095,
      "step": 1420
    },
    {
      "epoch": 1.45748987854251,
      "grad_norm": 0.972520649433136,
      "learning_rate": 3.5465587044534417e-05,
      "loss": 0.1108,
      "step": 1440
    },
    {
      "epoch": 1.4777327935222673,
      "grad_norm": 1.3663145303726196,
      "learning_rate": 3.526315789473684e-05,
      "loss": 0.1069,
      "step": 1460
    },
    {
      "epoch": 1.4979757085020242,
      "grad_norm": 1.9777629375457764,
      "learning_rate": 3.506072874493928e-05,
      "loss": 0.1227,
      "step": 1480
    },
    {
      "epoch": 1.5182186234817814,
      "grad_norm": 0.5192674398422241,
      "learning_rate": 3.48582995951417e-05,
      "loss": 0.0995,
      "step": 1500
    }
  ],
  "logging_steps": 20,
  "max_steps": 4940,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.256633860908646e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
