{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 3265,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.030627871362940276,
      "grad_norm": 2.1187944412231445,
      "learning_rate": 4.970903522205207e-05,
      "loss": 0.5299,
      "step": 20
    },
    {
      "epoch": 0.06125574272588055,
      "grad_norm": 1.980324149131775,
      "learning_rate": 4.9402756508422664e-05,
      "loss": 0.3022,
      "step": 40
    },
    {
      "epoch": 0.09188361408882083,
      "grad_norm": 2.759932041168213,
      "learning_rate": 4.9096477794793265e-05,
      "loss": 0.2105,
      "step": 60
    },
    {
      "epoch": 0.1225114854517611,
      "grad_norm": 3.57827091217041,
      "learning_rate": 4.879019908116386e-05,
      "loss": 0.2207,
      "step": 80
    },
    {
      "epoch": 0.15313935681470137,
      "grad_norm": 3.879436731338501,
      "learning_rate": 4.848392036753446e-05,
      "loss": 0.1959,
      "step": 100
    },
    {
      "epoch": 0.18376722817764166,
      "grad_norm": 1.116666555404663,
      "learning_rate": 4.8177641653905054e-05,
      "loss": 0.168,
      "step": 120
    },
    {
      "epoch": 0.21439509954058192,
      "grad_norm": 0.9540069103240967,
      "learning_rate": 4.7871362940275655e-05,
      "loss": 0.1402,
      "step": 140
    },
    {
      "epoch": 0.2450229709035222,
      "grad_norm": 4.23482608795166,
      "learning_rate": 4.756508422664625e-05,
      "loss": 0.1583,
      "step": 160
    },
    {
      "epoch": 0.27565084226646247,
      "grad_norm": 1.7619575262069702,
      "learning_rate": 4.7258805513016844e-05,
      "loss": 0.1378,
      "step": 180
    },
    {
      "epoch": 0.30627871362940273,
      "grad_norm": 1.5283914804458618,
      "learning_rate": 4.6952526799387445e-05,
      "loss": 0.1452,
      "step": 200
    },
    {
      "epoch": 0.33690658499234305,
      "grad_norm": 1.9734721183776855,
      "learning_rate": 4.6646248085758046e-05,
      "loss": 0.1309,
      "step": 220
    },
    {
      "epoch": 0.3675344563552833,
      "grad_norm": 9.578226089477539,
      "learning_rate": 4.633996937212864e-05,
      "loss": 0.163,
      "step": 240
    },
    {
      "epoch": 0.3981623277182236,
      "grad_norm": 0.7646257281303406,
      "learning_rate": 4.6033690658499234e-05,
      "loss": 0.1423,
      "step": 260
    },
    {
      "epoch": 0.42879019908116384,
      "grad_norm": 5.513787746429443,
      "learning_rate": 4.5727411944869836e-05,
      "loss": 0.1154,
      "step": 280
    },
    {
      "epoch": 0.45941807044410415,
      "grad_norm": 1.7930744886398315,
      "learning_rate": 4.542113323124043e-05,
      "loss": 0.1253,
      "step": 300
    },
    {
      "epoch": 0.4900459418070444,
      "grad_norm": 2.975278615951538,
      "learning_rate": 4.5114854517611024e-05,
      "loss": 0.1246,
      "step": 320
    },
    {
      "epoch": 0.5206738131699847,
      "grad_norm": 3.4944636821746826,
      "learning_rate": 4.4808575803981625e-05,
      "loss": 0.0986,
      "step": 340
    },
    {
      "epoch": 0.5513016845329249,
      "grad_norm": 0.9183768630027771,
      "learning_rate": 4.4502297090352226e-05,
      "loss": 0.0848,
      "step": 360
    },
    {
      "epoch": 0.5819295558958653,
      "grad_norm": 1.891306757926941,
      "learning_rate": 4.419601837672282e-05,
      "loss": 0.1183,
      "step": 380
    },
    {
      "epoch": 0.6125574272588055,
      "grad_norm": 1.0242429971694946,
      "learning_rate": 4.3889739663093415e-05,
      "loss": 0.0967,
      "step": 400
    },
    {
      "epoch": 0.6431852986217458,
      "grad_norm": 2.013988733291626,
      "learning_rate": 4.3583460949464016e-05,
      "loss": 0.0875,
      "step": 420
    },
    {
      "epoch": 0.6738131699846861,
      "grad_norm": 1.6906541585922241,
      "learning_rate": 4.327718223583461e-05,
      "loss": 0.0949,
      "step": 440
    },
    {
      "epoch": 0.7044410413476263,
      "grad_norm": 1.5570400953292847,
      "learning_rate": 4.297090352220521e-05,
      "loss": 0.1153,
      "step": 460
    },
    {
      "epoch": 0.7350689127105666,
      "grad_norm": 6.569056034088135,
      "learning_rate": 4.2664624808575805e-05,
      "loss": 0.1079,
      "step": 480
    },
    {
      "epoch": 0.7656967840735069,
      "grad_norm": 1.271204948425293,
      "learning_rate": 4.2358346094946406e-05,
      "loss": 0.0862,
      "step": 500
    },
    {
      "epoch": 0.7963246554364471,
      "grad_norm": 1.0544410943984985,
      "learning_rate": 4.2052067381317e-05,
      "loss": 0.0931,
      "step": 520
    },
    {
      "epoch": 0.8269525267993875,
      "grad_norm": 10.214714050292969,
      "learning_rate": 4.1745788667687595e-05,
      "loss": 0.0962,
      "step": 540
    },
    {
      "epoch": 0.8575803981623277,
      "grad_norm": 1.439218521118164,
      "learning_rate": 4.1439509954058196e-05,
      "loss": 0.0789,
      "step": 560
    },
    {
      "epoch": 0.888208269525268,
      "grad_norm": 5.214804649353027,
      "learning_rate": 4.113323124042879e-05,
      "loss": 0.0827,
      "step": 580
    },
    {
      "epoch": 0.9188361408882083,
      "grad_norm": 17.675701141357422,
      "learning_rate": 4.082695252679939e-05,
      "loss": 0.121,
      "step": 600
    },
    {
      "epoch": 0.9494640122511485,
      "grad_norm": 5.050410270690918,
      "learning_rate": 4.0520673813169986e-05,
      "loss": 0.091,
      "step": 620
    },
    {
      "epoch": 0.9800918836140888,
      "grad_norm": 0.3498417139053345,
      "learning_rate": 4.0214395099540587e-05,
      "loss": 0.0755,
      "step": 640
    },
    {
      "epoch": 1.010719754977029,
      "grad_norm": 5.65602445602417,
      "learning_rate": 3.990811638591118e-05,
      "loss": 0.0759,
      "step": 660
    },
    {
      "epoch": 1.0413476263399695,
      "grad_norm": 3.415013313293457,
      "learning_rate": 3.9601837672281775e-05,
      "loss": 0.0766,
      "step": 680
    },
    {
      "epoch": 1.0719754977029097,
      "grad_norm": 6.792565822601318,
      "learning_rate": 3.9295558958652376e-05,
      "loss": 0.0902,
      "step": 700
    },
    {
      "epoch": 1.1026033690658499,
      "grad_norm": 1.1162492036819458,
      "learning_rate": 3.898928024502298e-05,
      "loss": 0.0772,
      "step": 720
    },
    {
      "epoch": 1.13323124042879,
      "grad_norm": 3.495039939880371,
      "learning_rate": 3.868300153139357e-05,
      "loss": 0.0804,
      "step": 740
    },
    {
      "epoch": 1.1638591117917305,
      "grad_norm": 1.9195122718811035,
      "learning_rate": 3.8376722817764166e-05,
      "loss": 0.0694,
      "step": 760
    },
    {
      "epoch": 1.1944869831546707,
      "grad_norm": 3.8230910301208496,
      "learning_rate": 3.807044410413477e-05,
      "loss": 0.0663,
      "step": 780
    },
    {
      "epoch": 1.225114854517611,
      "grad_norm": 1.3276207447052002,
      "learning_rate": 3.776416539050536e-05,
      "loss": 0.0603,
      "step": 800
    },
    {
      "epoch": 1.2557427258805514,
      "grad_norm": 5.87797212600708,
      "learning_rate": 3.7457886676875955e-05,
      "loss": 0.1038,
      "step": 820
    },
    {
      "epoch": 1.2863705972434916,
      "grad_norm": 2.401761531829834,
      "learning_rate": 3.7151607963246556e-05,
      "loss": 0.0935,
      "step": 840
    },
    {
      "epoch": 1.3169984686064318,
      "grad_norm": 3.005131959915161,
      "learning_rate": 3.684532924961716e-05,
      "loss": 0.084,
      "step": 860
    },
    {
      "epoch": 1.3476263399693722,
      "grad_norm": 2.8746204376220703,
      "learning_rate": 3.653905053598775e-05,
      "loss": 0.0715,
      "step": 880
    },
    {
      "epoch": 1.3782542113323124,
      "grad_norm": 0.7922291159629822,
      "learning_rate": 3.6232771822358346e-05,
      "loss": 0.0572,
      "step": 900
    },
    {
      "epoch": 1.4088820826952526,
      "grad_norm": 3.29339861869812,
      "learning_rate": 3.592649310872894e-05,
      "loss": 0.0831,
      "step": 920
    },
    {
      "epoch": 1.439509954058193,
      "grad_norm": 2.9069955348968506,
      "learning_rate": 3.562021439509954e-05,
      "loss": 0.0698,
      "step": 940
    },
    {
      "epoch": 1.4701378254211332,
      "grad_norm": 2.413133382797241,
      "learning_rate": 3.531393568147014e-05,
      "loss": 0.0635,
      "step": 960
    },
    {
      "epoch": 1.5007656967840735,
      "grad_norm": 2.7178497314453125,
      "learning_rate": 3.500765696784074e-05,
      "loss": 0.0827,
      "step": 980
    },
    {
      "epoch": 1.5313935681470139,
      "grad_norm": 8.899578094482422,
      "learning_rate": 3.470137825421134e-05,
      "loss": 0.0678,
      "step": 1000
    },
    {
      "epoch": 1.562021439509954,
      "grad_norm": 1.2207777500152588,
      "learning_rate": 3.439509954058193e-05,
      "loss": 0.0808,
      "step": 1020
    },
    {
      "epoch": 1.5926493108728943,
      "grad_norm": 3.729206085205078,
      "learning_rate": 3.4088820826952526e-05,
      "loss": 0.0892,
      "step": 1040
    },
    {
      "epoch": 1.6232771822358347,
      "grad_norm": 1.3868739604949951,
      "learning_rate": 3.378254211332312e-05,
      "loss": 0.065,
      "step": 1060
    },
    {
      "epoch": 1.653905053598775,
      "grad_norm": 2.7512218952178955,
      "learning_rate": 3.347626339969372e-05,
      "loss": 0.0821,
      "step": 1080
    },
    {
      "epoch": 1.6845329249617151,
      "grad_norm": 1.4014923572540283,
      "learning_rate": 3.316998468606432e-05,
      "loss": 0.069,
      "step": 1100
    },
    {
      "epoch": 1.7151607963246556,
      "grad_norm": 3.569410562515259,
      "learning_rate": 3.286370597243492e-05,
      "loss": 0.0614,
      "step": 1120
    },
    {
      "epoch": 1.7457886676875956,
      "grad_norm": 0.9679320454597473,
      "learning_rate": 3.255742725880551e-05,
      "loss": 0.0666,
      "step": 1140
    },
    {
      "epoch": 1.776416539050536,
      "grad_norm": 9.285943984985352,
      "learning_rate": 3.225114854517611e-05,
      "loss": 0.0684,
      "step": 1160
    },
    {
      "epoch": 1.8070444104134764,
      "grad_norm": 3.3540146350860596,
      "learning_rate": 3.1944869831546706e-05,
      "loss": 0.0568,
      "step": 1180
    },
    {
      "epoch": 1.8376722817764164,
      "grad_norm": 3.085923910140991,
      "learning_rate": 3.163859111791731e-05,
      "loss": 0.0646,
      "step": 1200
    },
    {
      "epoch": 1.8683001531393568,
      "grad_norm": 1.128801703453064,
      "learning_rate": 3.133231240428791e-05,
      "loss": 0.0812,
      "step": 1220
    },
    {
      "epoch": 1.8989280245022973,
      "grad_norm": 1.0494872331619263,
      "learning_rate": 3.10260336906585e-05,
      "loss": 0.0611,
      "step": 1240
    },
    {
      "epoch": 1.9295558958652372,
      "grad_norm": 14.887206077575684,
      "learning_rate": 3.07197549770291e-05,
      "loss": 0.0604,
      "step": 1260
    },
    {
      "epoch": 1.9601837672281777,
      "grad_norm": 4.905717372894287,
      "learning_rate": 3.041347626339969e-05,
      "loss": 0.0644,
      "step": 1280
    },
    {
      "epoch": 1.9908116385911179,
      "grad_norm": 6.6682844161987305,
      "learning_rate": 3.0107197549770292e-05,
      "loss": 0.0541,
      "step": 1300
    },
    {
      "epoch": 2.021439509954058,
      "grad_norm": 1.4829835891723633,
      "learning_rate": 2.980091883614089e-05,
      "loss": 0.0642,
      "step": 1320
    },
    {
      "epoch": 2.0520673813169985,
      "grad_norm": 2.2748630046844482,
      "learning_rate": 2.9494640122511484e-05,
      "loss": 0.0527,
      "step": 1340
    },
    {
      "epoch": 2.082695252679939,
      "grad_norm": 1.6904592514038086,
      "learning_rate": 2.9188361408882085e-05,
      "loss": 0.0565,
      "step": 1360
    },
    {
      "epoch": 2.113323124042879,
      "grad_norm": 2.3715786933898926,
      "learning_rate": 2.8882082695252683e-05,
      "loss": 0.0686,
      "step": 1380
    },
    {
      "epoch": 2.1439509954058193,
      "grad_norm": 8.160995483398438,
      "learning_rate": 2.8575803981623277e-05,
      "loss": 0.0588,
      "step": 1400
    },
    {
      "epoch": 2.1745788667687598,
      "grad_norm": 1.886423945426941,
      "learning_rate": 2.8269525267993875e-05,
      "loss": 0.0591,
      "step": 1420
    },
    {
      "epoch": 2.2052067381316998,
      "grad_norm": 6.497519493103027,
      "learning_rate": 2.7963246554364476e-05,
      "loss": 0.0471,
      "step": 1440
    },
    {
      "epoch": 2.23583460949464,
      "grad_norm": 5.575425624847412,
      "learning_rate": 2.765696784073507e-05,
      "loss": 0.0619,
      "step": 1460
    },
    {
      "epoch": 2.26646248085758,
      "grad_norm": 8.443573951721191,
      "learning_rate": 2.7350689127105668e-05,
      "loss": 0.053,
      "step": 1480
    },
    {
      "epoch": 2.2970903522205206,
      "grad_norm": 1.3271656036376953,
      "learning_rate": 2.7044410413476262e-05,
      "loss": 0.0669,
      "step": 1500
    },
    {
      "epoch": 2.327718223583461,
      "grad_norm": 1.891379714012146,
      "learning_rate": 2.6738131699846863e-05,
      "loss": 0.0755,
      "step": 1520
    },
    {
      "epoch": 2.358346094946401,
      "grad_norm": 0.3526202142238617,
      "learning_rate": 2.6431852986217458e-05,
      "loss": 0.0523,
      "step": 1540
    },
    {
      "epoch": 2.3889739663093414,
      "grad_norm": 2.5373120307922363,
      "learning_rate": 2.6125574272588055e-05,
      "loss": 0.0473,
      "step": 1560
    },
    {
      "epoch": 2.419601837672282,
      "grad_norm": 2.9805221557617188,
      "learning_rate": 2.5819295558958656e-05,
      "loss": 0.0495,
      "step": 1580
    },
    {
      "epoch": 2.450229709035222,
      "grad_norm": 1.1753579378128052,
      "learning_rate": 2.551301684532925e-05,
      "loss": 0.0617,
      "step": 1600
    },
    {
      "epoch": 2.4808575803981623,
      "grad_norm": 1.7108054161071777,
      "learning_rate": 2.5206738131699848e-05,
      "loss": 0.128,
      "step": 1620
    },
    {
      "epoch": 2.5114854517611027,
      "grad_norm": 1.8542338609695435,
      "learning_rate": 2.4900459418070446e-05,
      "loss": 0.051,
      "step": 1640
    },
    {
      "epoch": 2.5421133231240427,
      "grad_norm": 11.172699928283691,
      "learning_rate": 2.459418070444104e-05,
      "loss": 0.0814,
      "step": 1660
    },
    {
      "epoch": 2.572741194486983,
      "grad_norm": 5.983081817626953,
      "learning_rate": 2.428790199081164e-05,
      "loss": 0.0492,
      "step": 1680
    },
    {
      "epoch": 2.6033690658499236,
      "grad_norm": 8.571494102478027,
      "learning_rate": 2.3981623277182235e-05,
      "loss": 0.0692,
      "step": 1700
    },
    {
      "epoch": 2.6339969372128635,
      "grad_norm": 0.7918572425842285,
      "learning_rate": 2.3675344563552833e-05,
      "loss": 0.0455,
      "step": 1720
    },
    {
      "epoch": 2.664624808575804,
      "grad_norm": 1.128729224205017,
      "learning_rate": 2.3369065849923434e-05,
      "loss": 0.0563,
      "step": 1740
    },
    {
      "epoch": 2.6952526799387444,
      "grad_norm": 7.129343032836914,
      "learning_rate": 2.306278713629403e-05,
      "loss": 0.0635,
      "step": 1760
    },
    {
      "epoch": 2.7258805513016844,
      "grad_norm": 2.712583303451538,
      "learning_rate": 2.2756508422664626e-05,
      "loss": 0.0517,
      "step": 1780
    },
    {
      "epoch": 2.756508422664625,
      "grad_norm": 2.727072238922119,
      "learning_rate": 2.2450229709035224e-05,
      "loss": 0.0421,
      "step": 1800
    },
    {
      "epoch": 2.7871362940275652,
      "grad_norm": 0.9352856278419495,
      "learning_rate": 2.214395099540582e-05,
      "loss": 0.0479,
      "step": 1820
    },
    {
      "epoch": 2.8177641653905052,
      "grad_norm": 9.601197242736816,
      "learning_rate": 2.1837672281776416e-05,
      "loss": 0.0435,
      "step": 1840
    },
    {
      "epoch": 2.8483920367534457,
      "grad_norm": 0.3486153483390808,
      "learning_rate": 2.1531393568147017e-05,
      "loss": 0.0423,
      "step": 1860
    },
    {
      "epoch": 2.879019908116386,
      "grad_norm": 2.297556161880493,
      "learning_rate": 2.122511485451761e-05,
      "loss": 0.0526,
      "step": 1880
    },
    {
      "epoch": 2.909647779479326,
      "grad_norm": 5.189900875091553,
      "learning_rate": 2.091883614088821e-05,
      "loss": 0.0576,
      "step": 1900
    },
    {
      "epoch": 2.9402756508422665,
      "grad_norm": 0.5996684432029724,
      "learning_rate": 2.0612557427258806e-05,
      "loss": 0.0561,
      "step": 1920
    },
    {
      "epoch": 2.970903522205207,
      "grad_norm": 0.5967084765434265,
      "learning_rate": 2.0306278713629404e-05,
      "loss": 0.0629,
      "step": 1940
    },
    {
      "epoch": 3.001531393568147,
      "grad_norm": 3.3175950050354004,
      "learning_rate": 2e-05,
      "loss": 0.0481,
      "step": 1960
    },
    {
      "epoch": 3.0321592649310873,
      "grad_norm": 1.3280317783355713,
      "learning_rate": 1.96937212863706e-05,
      "loss": 0.0543,
      "step": 1980
    },
    {
      "epoch": 3.0627871362940278,
      "grad_norm": 0.8093485832214355,
      "learning_rate": 1.9387442572741197e-05,
      "loss": 0.0479,
      "step": 2000
    },
    {
      "epoch": 3.0934150076569678,
      "grad_norm": 2.0568509101867676,
      "learning_rate": 1.908116385911179e-05,
      "loss": 0.0467,
      "step": 2020
    },
    {
      "epoch": 3.124042879019908,
      "grad_norm": 4.089011192321777,
      "learning_rate": 1.877488514548239e-05,
      "loss": 0.0406,
      "step": 2040
    },
    {
      "epoch": 3.1546707503828486,
      "grad_norm": 2.395798921585083,
      "learning_rate": 1.8468606431852987e-05,
      "loss": 0.0601,
      "step": 2060
    },
    {
      "epoch": 3.1852986217457886,
      "grad_norm": 9.658337593078613,
      "learning_rate": 1.8162327718223584e-05,
      "loss": 0.0427,
      "step": 2080
    },
    {
      "epoch": 3.215926493108729,
      "grad_norm": 0.29474061727523804,
      "learning_rate": 1.7856049004594182e-05,
      "loss": 0.0411,
      "step": 2100
    },
    {
      "epoch": 3.2465543644716695,
      "grad_norm": 2.3073678016662598,
      "learning_rate": 1.754977029096478e-05,
      "loss": 0.0534,
      "step": 2120
    },
    {
      "epoch": 3.2771822358346094,
      "grad_norm": 1.4316900968551636,
      "learning_rate": 1.7243491577335377e-05,
      "loss": 0.0426,
      "step": 2140
    },
    {
      "epoch": 3.30781010719755,
      "grad_norm": 3.3750317096710205,
      "learning_rate": 1.693721286370597e-05,
      "loss": 0.0464,
      "step": 2160
    },
    {
      "epoch": 3.3384379785604903,
      "grad_norm": 17.084516525268555,
      "learning_rate": 1.6630934150076573e-05,
      "loss": 0.0511,
      "step": 2180
    },
    {
      "epoch": 3.3690658499234303,
      "grad_norm": 0.7154364585876465,
      "learning_rate": 1.6324655436447167e-05,
      "loss": 0.0434,
      "step": 2200
    },
    {
      "epoch": 3.3996937212863707,
      "grad_norm": 4.090627670288086,
      "learning_rate": 1.6018376722817764e-05,
      "loss": 0.0528,
      "step": 2220
    },
    {
      "epoch": 3.4303215926493107,
      "grad_norm": 1.5671217441558838,
      "learning_rate": 1.5712098009188362e-05,
      "loss": 0.0702,
      "step": 2240
    },
    {
      "epoch": 3.460949464012251,
      "grad_norm": 0.9331842660903931,
      "learning_rate": 1.540581929555896e-05,
      "loss": 0.0512,
      "step": 2260
    },
    {
      "epoch": 3.4915773353751915,
      "grad_norm": 0.6076580882072449,
      "learning_rate": 1.5099540581929556e-05,
      "loss": 0.0328,
      "step": 2280
    },
    {
      "epoch": 3.522205206738132,
      "grad_norm": 4.077247619628906,
      "learning_rate": 1.4793261868300153e-05,
      "loss": 0.078,
      "step": 2300
    },
    {
      "epoch": 3.552833078101072,
      "grad_norm": 3.152468204498291,
      "learning_rate": 1.4486983154670753e-05,
      "loss": 0.0641,
      "step": 2320
    },
    {
      "epoch": 3.5834609494640124,
      "grad_norm": 0.48687681555747986,
      "learning_rate": 1.4180704441041349e-05,
      "loss": 0.0384,
      "step": 2340
    },
    {
      "epoch": 3.6140888208269524,
      "grad_norm": 1.5655066967010498,
      "learning_rate": 1.3874425727411946e-05,
      "loss": 0.0395,
      "step": 2360
    },
    {
      "epoch": 3.644716692189893,
      "grad_norm": 4.345086097717285,
      "learning_rate": 1.3568147013782542e-05,
      "loss": 0.0425,
      "step": 2380
    },
    {
      "epoch": 3.6753445635528332,
      "grad_norm": 11.426301956176758,
      "learning_rate": 1.326186830015314e-05,
      "loss": 0.0586,
      "step": 2400
    },
    {
      "epoch": 3.705972434915773,
      "grad_norm": 1.8672220706939697,
      "learning_rate": 1.2955589586523736e-05,
      "loss": 0.0371,
      "step": 2420
    },
    {
      "epoch": 3.7366003062787136,
      "grad_norm": 4.031021595001221,
      "learning_rate": 1.2649310872894335e-05,
      "loss": 0.0361,
      "step": 2440
    },
    {
      "epoch": 3.7672281776416536,
      "grad_norm": 0.6018697023391724,
      "learning_rate": 1.2343032159264931e-05,
      "loss": 0.0435,
      "step": 2460
    },
    {
      "epoch": 3.797856049004594,
      "grad_norm": 7.3046159744262695,
      "learning_rate": 1.2036753445635529e-05,
      "loss": 0.0342,
      "step": 2480
    },
    {
      "epoch": 3.8284839203675345,
      "grad_norm": 1.5135833024978638,
      "learning_rate": 1.1730474732006127e-05,
      "loss": 0.0349,
      "step": 2500
    },
    {
      "epoch": 3.8591117917304745,
      "grad_norm": 6.033401966094971,
      "learning_rate": 1.1424196018376723e-05,
      "loss": 0.0775,
      "step": 2520
    },
    {
      "epoch": 3.889739663093415,
      "grad_norm": 1.4378093481063843,
      "learning_rate": 1.111791730474732e-05,
      "loss": 0.0385,
      "step": 2540
    },
    {
      "epoch": 3.9203675344563553,
      "grad_norm": 0.6960663795471191,
      "learning_rate": 1.0811638591117918e-05,
      "loss": 0.0418,
      "step": 2560
    },
    {
      "epoch": 3.9509954058192953,
      "grad_norm": 4.134684085845947,
      "learning_rate": 1.0505359877488514e-05,
      "loss": 0.0458,
      "step": 2580
    },
    {
      "epoch": 3.9816232771822357,
      "grad_norm": 2.267778158187866,
      "learning_rate": 1.0199081163859111e-05,
      "loss": 0.0518,
      "step": 2600
    },
    {
      "epoch": 4.012251148545176,
      "grad_norm": 1.7217684984207153,
      "learning_rate": 9.89280245022971e-06,
      "loss": 0.0404,
      "step": 2620
    },
    {
      "epoch": 4.042879019908116,
      "grad_norm": 2.271341323852539,
      "learning_rate": 9.586523736600307e-06,
      "loss": 0.0339,
      "step": 2640
    },
    {
      "epoch": 4.073506891271057,
      "grad_norm": 0.6621776819229126,
      "learning_rate": 9.280245022970904e-06,
      "loss": 0.0451,
      "step": 2660
    },
    {
      "epoch": 4.104134762633997,
      "grad_norm": 0.943083643913269,
      "learning_rate": 8.973966309341502e-06,
      "loss": 0.0406,
      "step": 2680
    },
    {
      "epoch": 4.134762633996937,
      "grad_norm": 0.8341229557991028,
      "learning_rate": 8.667687595712098e-06,
      "loss": 0.0422,
      "step": 2700
    },
    {
      "epoch": 4.165390505359878,
      "grad_norm": 0.7487266659736633,
      "learning_rate": 8.361408882082696e-06,
      "loss": 0.0425,
      "step": 2720
    },
    {
      "epoch": 4.196018376722818,
      "grad_norm": 0.5102624297142029,
      "learning_rate": 8.055130168453293e-06,
      "loss": 0.0401,
      "step": 2740
    },
    {
      "epoch": 4.226646248085758,
      "grad_norm": 1.421216607093811,
      "learning_rate": 7.74885145482389e-06,
      "loss": 0.0778,
      "step": 2760
    },
    {
      "epoch": 4.257274119448699,
      "grad_norm": 1.3995165824890137,
      "learning_rate": 7.442572741194487e-06,
      "loss": 0.0348,
      "step": 2780
    },
    {
      "epoch": 4.287901990811639,
      "grad_norm": 1.6407922506332397,
      "learning_rate": 7.1362940275650855e-06,
      "loss": 0.0467,
      "step": 2800
    },
    {
      "epoch": 4.318529862174579,
      "grad_norm": 1.0831177234649658,
      "learning_rate": 6.830015313935682e-06,
      "loss": 0.0475,
      "step": 2820
    },
    {
      "epoch": 4.3491577335375196,
      "grad_norm": 1.861807107925415,
      "learning_rate": 6.523736600306279e-06,
      "loss": 0.0351,
      "step": 2840
    },
    {
      "epoch": 4.3797856049004595,
      "grad_norm": 2.468013286590576,
      "learning_rate": 6.217457886676877e-06,
      "loss": 0.0378,
      "step": 2860
    },
    {
      "epoch": 4.4104134762633995,
      "grad_norm": 4.0216288566589355,
      "learning_rate": 5.911179173047474e-06,
      "loss": 0.0382,
      "step": 2880
    },
    {
      "epoch": 4.44104134762634,
      "grad_norm": 2.360146999359131,
      "learning_rate": 5.6049004594180705e-06,
      "loss": 0.0403,
      "step": 2900
    },
    {
      "epoch": 4.47166921898928,
      "grad_norm": 3.7833049297332764,
      "learning_rate": 5.298621745788668e-06,
      "loss": 0.0931,
      "step": 2920
    },
    {
      "epoch": 4.50229709035222,
      "grad_norm": 4.357768535614014,
      "learning_rate": 4.992343032159265e-06,
      "loss": 0.0452,
      "step": 2940
    },
    {
      "epoch": 4.53292496171516,
      "grad_norm": 1.314254641532898,
      "learning_rate": 4.686064318529863e-06,
      "loss": 0.0319,
      "step": 2960
    },
    {
      "epoch": 4.563552833078101,
      "grad_norm": 0.7490384578704834,
      "learning_rate": 4.379785604900459e-06,
      "loss": 0.0394,
      "step": 2980
    },
    {
      "epoch": 4.594180704441041,
      "grad_norm": 0.4670158922672272,
      "learning_rate": 4.073506891271057e-06,
      "loss": 0.0416,
      "step": 3000
    },
    {
      "epoch": 4.624808575803982,
      "grad_norm": 0.290399968624115,
      "learning_rate": 3.767228177641654e-06,
      "loss": 0.0491,
      "step": 3020
    },
    {
      "epoch": 4.655436447166922,
      "grad_norm": 0.9831076264381409,
      "learning_rate": 3.460949464012251e-06,
      "loss": 0.0436,
      "step": 3040
    },
    {
      "epoch": 4.686064318529862,
      "grad_norm": 11.28018856048584,
      "learning_rate": 3.1546707503828488e-06,
      "loss": 0.0785,
      "step": 3060
    },
    {
      "epoch": 4.716692189892802,
      "grad_norm": 0.4248942732810974,
      "learning_rate": 2.848392036753446e-06,
      "loss": 0.0338,
      "step": 3080
    },
    {
      "epoch": 4.747320061255743,
      "grad_norm": 0.9479392766952515,
      "learning_rate": 2.542113323124043e-06,
      "loss": 0.034,
      "step": 3100
    },
    {
      "epoch": 4.777947932618683,
      "grad_norm": 0.5383313894271851,
      "learning_rate": 2.2358346094946405e-06,
      "loss": 0.0354,
      "step": 3120
    },
    {
      "epoch": 4.808575803981624,
      "grad_norm": 3.3199422359466553,
      "learning_rate": 1.9295558958652373e-06,
      "loss": 0.0344,
      "step": 3140
    },
    {
      "epoch": 4.839203675344564,
      "grad_norm": 1.2476661205291748,
      "learning_rate": 1.6232771822358345e-06,
      "loss": 0.04,
      "step": 3160
    },
    {
      "epoch": 4.869831546707504,
      "grad_norm": 0.8201155066490173,
      "learning_rate": 1.316998468606432e-06,
      "loss": 0.0365,
      "step": 3180
    },
    {
      "epoch": 4.900459418070444,
      "grad_norm": 3.954815149307251,
      "learning_rate": 1.010719754977029e-06,
      "loss": 0.0436,
      "step": 3200
    },
    {
      "epoch": 4.931087289433385,
      "grad_norm": 9.224310874938965,
      "learning_rate": 7.044410413476264e-07,
      "loss": 0.0411,
      "step": 3220
    },
    {
      "epoch": 4.961715160796325,
      "grad_norm": 1.2389919757843018,
      "learning_rate": 3.9816232771822357e-07,
      "loss": 0.0324,
      "step": 3240
    },
    {
      "epoch": 4.992343032159265,
      "grad_norm": 1.2170097827911377,
      "learning_rate": 9.188361408882083e-08,
      "loss": 0.0386,
      "step": 3260
    }
  ],
  "logging_steps": 20,
  "max_steps": 3265,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.2891509911126016e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
