{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.048582995951417,
  "eval_steps": 500,
  "global_step": 4000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.020242914979757085,
      "grad_norm": 2.60353684425354,
      "learning_rate": 4.980769230769231e-05,
      "loss": 0.5543,
      "step": 20
    },
    {
      "epoch": 0.04048582995951417,
      "grad_norm": 1.4951989650726318,
      "learning_rate": 4.960526315789474e-05,
      "loss": 0.3538,
      "step": 40
    },
    {
      "epoch": 0.06072874493927125,
      "grad_norm": 1.2178782224655151,
      "learning_rate": 4.940283400809717e-05,
      "loss": 0.2834,
      "step": 60
    },
    {
      "epoch": 0.08097165991902834,
      "grad_norm": 1.408525824546814,
      "learning_rate": 4.92004048582996e-05,
      "loss": 0.2507,
      "step": 80
    },
    {
      "epoch": 0.10121457489878542,
      "grad_norm": 2.4710991382598877,
      "learning_rate": 4.899797570850202e-05,
      "loss": 0.232,
      "step": 100
    },
    {
      "epoch": 0.1214574898785425,
      "grad_norm": 1.517261028289795,
      "learning_rate": 4.879554655870446e-05,
      "loss": 0.1583,
      "step": 120
    },
    {
      "epoch": 0.1417004048582996,
      "grad_norm": 2.8705952167510986,
      "learning_rate": 4.8603238866396764e-05,
      "loss": 0.2336,
      "step": 140
    },
    {
      "epoch": 0.16194331983805668,
      "grad_norm": 2.681584358215332,
      "learning_rate": 4.8400809716599195e-05,
      "loss": 0.1664,
      "step": 160
    },
    {
      "epoch": 0.18218623481781376,
      "grad_norm": 1.6810041666030884,
      "learning_rate": 4.819838056680162e-05,
      "loss": 0.2291,
      "step": 180
    },
    {
      "epoch": 0.20242914979757085,
      "grad_norm": 2.6532223224639893,
      "learning_rate": 4.7995951417004056e-05,
      "loss": 0.1705,
      "step": 200
    },
    {
      "epoch": 0.22267206477732793,
      "grad_norm": 2.7997703552246094,
      "learning_rate": 4.779352226720648e-05,
      "loss": 0.151,
      "step": 220
    },
    {
      "epoch": 0.242914979757085,
      "grad_norm": 4.134150981903076,
      "learning_rate": 4.759109311740891e-05,
      "loss": 0.1737,
      "step": 240
    },
    {
      "epoch": 0.2631578947368421,
      "grad_norm": 6.276228427886963,
      "learning_rate": 4.738866396761134e-05,
      "loss": 0.1654,
      "step": 260
    },
    {
      "epoch": 0.2834008097165992,
      "grad_norm": 1.7194103002548218,
      "learning_rate": 4.7186234817813765e-05,
      "loss": 0.1279,
      "step": 280
    },
    {
      "epoch": 0.30364372469635625,
      "grad_norm": 3.241950511932373,
      "learning_rate": 4.6983805668016196e-05,
      "loss": 0.1641,
      "step": 300
    },
    {
      "epoch": 0.32388663967611336,
      "grad_norm": 9.388757705688477,
      "learning_rate": 4.6781376518218626e-05,
      "loss": 0.2066,
      "step": 320
    },
    {
      "epoch": 0.3441295546558704,
      "grad_norm": 0.6280366778373718,
      "learning_rate": 4.658906882591093e-05,
      "loss": 0.1364,
      "step": 340
    },
    {
      "epoch": 0.3643724696356275,
      "grad_norm": 4.365753650665283,
      "learning_rate": 4.638663967611336e-05,
      "loss": 0.1371,
      "step": 360
    },
    {
      "epoch": 0.38461538461538464,
      "grad_norm": 8.496685028076172,
      "learning_rate": 4.618421052631579e-05,
      "loss": 0.1191,
      "step": 380
    },
    {
      "epoch": 0.4048582995951417,
      "grad_norm": 8.699529647827148,
      "learning_rate": 4.5981781376518216e-05,
      "loss": 0.1495,
      "step": 400
    },
    {
      "epoch": 0.4251012145748988,
      "grad_norm": 5.345395565032959,
      "learning_rate": 4.577935222672065e-05,
      "loss": 0.1394,
      "step": 420
    },
    {
      "epoch": 0.44534412955465585,
      "grad_norm": 4.354844570159912,
      "learning_rate": 4.557692307692308e-05,
      "loss": 0.1314,
      "step": 440
    },
    {
      "epoch": 0.46558704453441296,
      "grad_norm": 7.832252025604248,
      "learning_rate": 4.537449392712551e-05,
      "loss": 0.1813,
      "step": 460
    },
    {
      "epoch": 0.48582995951417,
      "grad_norm": 0.4733159840106964,
      "learning_rate": 4.517206477732794e-05,
      "loss": 0.1474,
      "step": 480
    },
    {
      "epoch": 0.5060728744939271,
      "grad_norm": 4.4916768074035645,
      "learning_rate": 4.496963562753036e-05,
      "loss": 0.1178,
      "step": 500
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 6.250394344329834,
      "learning_rate": 4.47672064777328e-05,
      "loss": 0.1279,
      "step": 520
    },
    {
      "epoch": 0.5465587044534413,
      "grad_norm": 1.0069736242294312,
      "learning_rate": 4.4564777327935224e-05,
      "loss": 0.127,
      "step": 540
    },
    {
      "epoch": 0.5668016194331984,
      "grad_norm": 2.2202513217926025,
      "learning_rate": 4.4362348178137654e-05,
      "loss": 0.1244,
      "step": 560
    },
    {
      "epoch": 0.5870445344129555,
      "grad_norm": 2.029829978942871,
      "learning_rate": 4.4159919028340085e-05,
      "loss": 0.1545,
      "step": 580
    },
    {
      "epoch": 0.6072874493927125,
      "grad_norm": 1.6138578653335571,
      "learning_rate": 4.3957489878542516e-05,
      "loss": 0.1674,
      "step": 600
    },
    {
      "epoch": 0.6275303643724697,
      "grad_norm": 3.7324604988098145,
      "learning_rate": 4.375506072874494e-05,
      "loss": 0.1436,
      "step": 620
    },
    {
      "epoch": 0.6477732793522267,
      "grad_norm": 4.236327648162842,
      "learning_rate": 4.356275303643725e-05,
      "loss": 0.1317,
      "step": 640
    },
    {
      "epoch": 0.6680161943319838,
      "grad_norm": 11.883174896240234,
      "learning_rate": 4.3360323886639674e-05,
      "loss": 0.1609,
      "step": 660
    },
    {
      "epoch": 0.6882591093117408,
      "grad_norm": 1.322102665901184,
      "learning_rate": 4.3157894736842105e-05,
      "loss": 0.1057,
      "step": 680
    },
    {
      "epoch": 0.708502024291498,
      "grad_norm": 3.9290645122528076,
      "learning_rate": 4.2955465587044536e-05,
      "loss": 0.1542,
      "step": 700
    },
    {
      "epoch": 0.728744939271255,
      "grad_norm": 2.389382839202881,
      "learning_rate": 4.2753036437246966e-05,
      "loss": 0.1145,
      "step": 720
    },
    {
      "epoch": 0.7489878542510121,
      "grad_norm": 0.7864636778831482,
      "learning_rate": 4.25506072874494e-05,
      "loss": 0.0963,
      "step": 740
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 1.3286188840866089,
      "learning_rate": 4.234817813765182e-05,
      "loss": 0.1284,
      "step": 760
    },
    {
      "epoch": 0.7894736842105263,
      "grad_norm": 7.57919454574585,
      "learning_rate": 4.214574898785426e-05,
      "loss": 0.1308,
      "step": 780
    },
    {
      "epoch": 0.8097165991902834,
      "grad_norm": 5.662615776062012,
      "learning_rate": 4.194331983805668e-05,
      "loss": 0.1644,
      "step": 800
    },
    {
      "epoch": 0.8299595141700404,
      "grad_norm": 6.5239410400390625,
      "learning_rate": 4.174089068825911e-05,
      "loss": 0.1093,
      "step": 820
    },
    {
      "epoch": 0.8502024291497976,
      "grad_norm": 0.7537091970443726,
      "learning_rate": 4.1538461538461544e-05,
      "loss": 0.1293,
      "step": 840
    },
    {
      "epoch": 0.8704453441295547,
      "grad_norm": 1.4398534297943115,
      "learning_rate": 4.133603238866397e-05,
      "loss": 0.1366,
      "step": 860
    },
    {
      "epoch": 0.8906882591093117,
      "grad_norm": 1.0573694705963135,
      "learning_rate": 4.11336032388664e-05,
      "loss": 0.1181,
      "step": 880
    },
    {
      "epoch": 0.9109311740890689,
      "grad_norm": 1.6042877435684204,
      "learning_rate": 4.093117408906883e-05,
      "loss": 0.1556,
      "step": 900
    },
    {
      "epoch": 0.9311740890688259,
      "grad_norm": 1.6729271411895752,
      "learning_rate": 4.072874493927126e-05,
      "loss": 0.0979,
      "step": 920
    },
    {
      "epoch": 0.951417004048583,
      "grad_norm": 1.523969054222107,
      "learning_rate": 4.0526315789473684e-05,
      "loss": 0.1277,
      "step": 940
    },
    {
      "epoch": 0.97165991902834,
      "grad_norm": 5.040785312652588,
      "learning_rate": 4.0323886639676114e-05,
      "loss": 0.1036,
      "step": 960
    },
    {
      "epoch": 0.9919028340080972,
      "grad_norm": 2.866434097290039,
      "learning_rate": 4.0121457489878545e-05,
      "loss": 0.1359,
      "step": 980
    },
    {
      "epoch": 1.0121457489878543,
      "grad_norm": 3.0122830867767334,
      "learning_rate": 3.991902834008097e-05,
      "loss": 0.1335,
      "step": 1000
    },
    {
      "epoch": 1.0323886639676114,
      "grad_norm": 0.7991473078727722,
      "learning_rate": 3.9716599190283406e-05,
      "loss": 0.1215,
      "step": 1020
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 1.5124045610427856,
      "learning_rate": 3.951417004048583e-05,
      "loss": 0.0833,
      "step": 1040
    },
    {
      "epoch": 1.0728744939271255,
      "grad_norm": 0.8686792254447937,
      "learning_rate": 3.931174089068826e-05,
      "loss": 0.0868,
      "step": 1060
    },
    {
      "epoch": 1.0931174089068827,
      "grad_norm": 0.6204802989959717,
      "learning_rate": 3.910931174089069e-05,
      "loss": 0.1123,
      "step": 1080
    },
    {
      "epoch": 1.1133603238866396,
      "grad_norm": 1.5977180004119873,
      "learning_rate": 3.890688259109312e-05,
      "loss": 0.0891,
      "step": 1100
    },
    {
      "epoch": 1.1336032388663968,
      "grad_norm": 1.9436721801757812,
      "learning_rate": 3.8704453441295546e-05,
      "loss": 0.0985,
      "step": 1120
    },
    {
      "epoch": 1.1538461538461537,
      "grad_norm": 1.1701987981796265,
      "learning_rate": 3.850202429149798e-05,
      "loss": 0.1505,
      "step": 1140
    },
    {
      "epoch": 1.174089068825911,
      "grad_norm": 17.12029266357422,
      "learning_rate": 3.829959514170041e-05,
      "loss": 0.1285,
      "step": 1160
    },
    {
      "epoch": 1.194331983805668,
      "grad_norm": 8.780117988586426,
      "learning_rate": 3.809716599190283e-05,
      "loss": 0.1086,
      "step": 1180
    },
    {
      "epoch": 1.214574898785425,
      "grad_norm": 0.9133884310722351,
      "learning_rate": 3.789473684210527e-05,
      "loss": 0.1054,
      "step": 1200
    },
    {
      "epoch": 1.2348178137651822,
      "grad_norm": 0.4866701662540436,
      "learning_rate": 3.769230769230769e-05,
      "loss": 0.0641,
      "step": 1220
    },
    {
      "epoch": 1.2550607287449393,
      "grad_norm": 0.8039166927337646,
      "learning_rate": 3.748987854251012e-05,
      "loss": 0.1268,
      "step": 1240
    },
    {
      "epoch": 1.2753036437246963,
      "grad_norm": 5.949751377105713,
      "learning_rate": 3.7287449392712554e-05,
      "loss": 0.1019,
      "step": 1260
    },
    {
      "epoch": 1.2955465587044535,
      "grad_norm": 0.2436349242925644,
      "learning_rate": 3.708502024291498e-05,
      "loss": 0.1134,
      "step": 1280
    },
    {
      "epoch": 1.3157894736842106,
      "grad_norm": 0.3876831531524658,
      "learning_rate": 3.688259109311741e-05,
      "loss": 0.0828,
      "step": 1300
    },
    {
      "epoch": 1.3360323886639676,
      "grad_norm": 1.0606331825256348,
      "learning_rate": 3.668016194331984e-05,
      "loss": 0.0899,
      "step": 1320
    },
    {
      "epoch": 1.3562753036437247,
      "grad_norm": 1.8161728382110596,
      "learning_rate": 3.647773279352227e-05,
      "loss": 0.1133,
      "step": 1340
    },
    {
      "epoch": 1.376518218623482,
      "grad_norm": 2.027841329574585,
      "learning_rate": 3.62753036437247e-05,
      "loss": 0.0958,
      "step": 1360
    },
    {
      "epoch": 1.3967611336032388,
      "grad_norm": 2.5625786781311035,
      "learning_rate": 3.607287449392713e-05,
      "loss": 0.0848,
      "step": 1380
    },
    {
      "epoch": 1.417004048582996,
      "grad_norm": 1.9966802597045898,
      "learning_rate": 3.5870445344129555e-05,
      "loss": 0.086,
      "step": 1400
    },
    {
      "epoch": 1.4372469635627532,
      "grad_norm": 2.6053574085235596,
      "learning_rate": 3.5668016194331986e-05,
      "loss": 0.095,
      "step": 1420
    },
    {
      "epoch": 1.45748987854251,
      "grad_norm": 0.972520649433136,
      "learning_rate": 3.5465587044534417e-05,
      "loss": 0.1108,
      "step": 1440
    },
    {
      "epoch": 1.4777327935222673,
      "grad_norm": 1.3663145303726196,
      "learning_rate": 3.526315789473684e-05,
      "loss": 0.1069,
      "step": 1460
    },
    {
      "epoch": 1.4979757085020242,
      "grad_norm": 1.9777629375457764,
      "learning_rate": 3.506072874493928e-05,
      "loss": 0.1227,
      "step": 1480
    },
    {
      "epoch": 1.5182186234817814,
      "grad_norm": 0.5192674398422241,
      "learning_rate": 3.48582995951417e-05,
      "loss": 0.0995,
      "step": 1500
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 3.5324535369873047,
      "learning_rate": 3.465587044534413e-05,
      "loss": 0.1126,
      "step": 1520
    },
    {
      "epoch": 1.5587044534412957,
      "grad_norm": 2.2765111923217773,
      "learning_rate": 3.445344129554656e-05,
      "loss": 0.1104,
      "step": 1540
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 4.693960189819336,
      "learning_rate": 3.425101214574899e-05,
      "loss": 0.0947,
      "step": 1560
    },
    {
      "epoch": 1.5991902834008096,
      "grad_norm": 1.0367261171340942,
      "learning_rate": 3.404858299595142e-05,
      "loss": 0.0972,
      "step": 1580
    },
    {
      "epoch": 1.6194331983805668,
      "grad_norm": 4.909794330596924,
      "learning_rate": 3.384615384615385e-05,
      "loss": 0.1032,
      "step": 1600
    },
    {
      "epoch": 1.639676113360324,
      "grad_norm": 4.734772205352783,
      "learning_rate": 3.364372469635628e-05,
      "loss": 0.0913,
      "step": 1620
    },
    {
      "epoch": 1.6599190283400809,
      "grad_norm": 1.2564631700515747,
      "learning_rate": 3.34412955465587e-05,
      "loss": 0.0947,
      "step": 1640
    },
    {
      "epoch": 1.680161943319838,
      "grad_norm": 2.455995559692383,
      "learning_rate": 3.3238866396761134e-05,
      "loss": 0.1341,
      "step": 1660
    },
    {
      "epoch": 1.7004048582995952,
      "grad_norm": 3.4936025142669678,
      "learning_rate": 3.3036437246963564e-05,
      "loss": 0.102,
      "step": 1680
    },
    {
      "epoch": 1.7206477732793521,
      "grad_norm": 5.708625316619873,
      "learning_rate": 3.283400809716599e-05,
      "loss": 0.1311,
      "step": 1700
    },
    {
      "epoch": 1.7408906882591093,
      "grad_norm": 8.04496955871582,
      "learning_rate": 3.2631578947368426e-05,
      "loss": 0.0973,
      "step": 1720
    },
    {
      "epoch": 1.7611336032388665,
      "grad_norm": 0.42990007996559143,
      "learning_rate": 3.242914979757085e-05,
      "loss": 0.0778,
      "step": 1740
    },
    {
      "epoch": 1.7813765182186234,
      "grad_norm": 0.5142814517021179,
      "learning_rate": 3.222672064777328e-05,
      "loss": 0.0835,
      "step": 1760
    },
    {
      "epoch": 1.8016194331983806,
      "grad_norm": 3.7256152629852295,
      "learning_rate": 3.202429149797571e-05,
      "loss": 0.1264,
      "step": 1780
    },
    {
      "epoch": 1.8218623481781377,
      "grad_norm": 2.2061614990234375,
      "learning_rate": 3.182186234817814e-05,
      "loss": 0.0866,
      "step": 1800
    },
    {
      "epoch": 1.8421052631578947,
      "grad_norm": 9.812321662902832,
      "learning_rate": 3.1619433198380566e-05,
      "loss": 0.1289,
      "step": 1820
    },
    {
      "epoch": 1.8623481781376519,
      "grad_norm": 4.329840660095215,
      "learning_rate": 3.1417004048582996e-05,
      "loss": 0.1401,
      "step": 1840
    },
    {
      "epoch": 1.882591093117409,
      "grad_norm": 3.1781063079833984,
      "learning_rate": 3.121457489878543e-05,
      "loss": 0.1147,
      "step": 1860
    },
    {
      "epoch": 1.902834008097166,
      "grad_norm": 4.145416259765625,
      "learning_rate": 3.101214574898785e-05,
      "loss": 0.0707,
      "step": 1880
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 4.064936637878418,
      "learning_rate": 3.080971659919029e-05,
      "loss": 0.0941,
      "step": 1900
    },
    {
      "epoch": 1.9433198380566803,
      "grad_norm": 0.2696869969367981,
      "learning_rate": 3.060728744939271e-05,
      "loss": 0.074,
      "step": 1920
    },
    {
      "epoch": 1.9635627530364372,
      "grad_norm": 7.998841285705566,
      "learning_rate": 3.0404858299595146e-05,
      "loss": 0.0917,
      "step": 1940
    },
    {
      "epoch": 1.9838056680161942,
      "grad_norm": 34.24335861206055,
      "learning_rate": 3.0202429149797573e-05,
      "loss": 0.1226,
      "step": 1960
    },
    {
      "epoch": 2.0040485829959516,
      "grad_norm": 0.6935098171234131,
      "learning_rate": 3e-05,
      "loss": 0.0893,
      "step": 1980
    },
    {
      "epoch": 2.0242914979757085,
      "grad_norm": 1.8242509365081787,
      "learning_rate": 2.979757085020243e-05,
      "loss": 0.0472,
      "step": 2000
    },
    {
      "epoch": 2.0445344129554655,
      "grad_norm": 1.7249743938446045,
      "learning_rate": 2.959514170040486e-05,
      "loss": 0.1042,
      "step": 2020
    },
    {
      "epoch": 2.064777327935223,
      "grad_norm": 1.1615363359451294,
      "learning_rate": 2.9392712550607286e-05,
      "loss": 0.1078,
      "step": 2040
    },
    {
      "epoch": 2.08502024291498,
      "grad_norm": 0.46546974778175354,
      "learning_rate": 2.919028340080972e-05,
      "loss": 0.0737,
      "step": 2060
    },
    {
      "epoch": 2.1052631578947367,
      "grad_norm": 0.5528144836425781,
      "learning_rate": 2.8987854251012147e-05,
      "loss": 0.1014,
      "step": 2080
    },
    {
      "epoch": 2.125506072874494,
      "grad_norm": 10.286727905273438,
      "learning_rate": 2.8785425101214575e-05,
      "loss": 0.0898,
      "step": 2100
    },
    {
      "epoch": 2.145748987854251,
      "grad_norm": 1.3573384284973145,
      "learning_rate": 2.858299595141701e-05,
      "loss": 0.0889,
      "step": 2120
    },
    {
      "epoch": 2.165991902834008,
      "grad_norm": 1.112186312675476,
      "learning_rate": 2.8380566801619436e-05,
      "loss": 0.0787,
      "step": 2140
    },
    {
      "epoch": 2.1862348178137654,
      "grad_norm": 2.859551191329956,
      "learning_rate": 2.8178137651821863e-05,
      "loss": 0.0802,
      "step": 2160
    },
    {
      "epoch": 2.2064777327935223,
      "grad_norm": 0.6965360045433044,
      "learning_rate": 2.7975708502024294e-05,
      "loss": 0.0755,
      "step": 2180
    },
    {
      "epoch": 2.2267206477732793,
      "grad_norm": 2.935131549835205,
      "learning_rate": 2.777327935222672e-05,
      "loss": 0.071,
      "step": 2200
    },
    {
      "epoch": 2.246963562753036,
      "grad_norm": 9.088553428649902,
      "learning_rate": 2.757085020242915e-05,
      "loss": 0.0619,
      "step": 2220
    },
    {
      "epoch": 2.2672064777327936,
      "grad_norm": 0.5289122462272644,
      "learning_rate": 2.7368421052631583e-05,
      "loss": 0.0839,
      "step": 2240
    },
    {
      "epoch": 2.2874493927125505,
      "grad_norm": 0.3528498411178589,
      "learning_rate": 2.716599190283401e-05,
      "loss": 0.0816,
      "step": 2260
    },
    {
      "epoch": 2.3076923076923075,
      "grad_norm": 1.907210111618042,
      "learning_rate": 2.6963562753036437e-05,
      "loss": 0.0671,
      "step": 2280
    },
    {
      "epoch": 2.327935222672065,
      "grad_norm": 2.901934862136841,
      "learning_rate": 2.6761133603238868e-05,
      "loss": 0.0761,
      "step": 2300
    },
    {
      "epoch": 2.348178137651822,
      "grad_norm": 1.4834688901901245,
      "learning_rate": 2.6558704453441295e-05,
      "loss": 0.0839,
      "step": 2320
    },
    {
      "epoch": 2.3684210526315788,
      "grad_norm": 1.0534882545471191,
      "learning_rate": 2.6356275303643722e-05,
      "loss": 0.1038,
      "step": 2340
    },
    {
      "epoch": 2.388663967611336,
      "grad_norm": 0.512983500957489,
      "learning_rate": 2.6153846153846157e-05,
      "loss": 0.0918,
      "step": 2360
    },
    {
      "epoch": 2.408906882591093,
      "grad_norm": 3.5520126819610596,
      "learning_rate": 2.5951417004048584e-05,
      "loss": 0.0801,
      "step": 2380
    },
    {
      "epoch": 2.42914979757085,
      "grad_norm": 7.9033002853393555,
      "learning_rate": 2.574898785425101e-05,
      "loss": 0.102,
      "step": 2400
    },
    {
      "epoch": 2.4493927125506074,
      "grad_norm": 3.79817271232605,
      "learning_rate": 2.5546558704453445e-05,
      "loss": 0.0677,
      "step": 2420
    },
    {
      "epoch": 2.4696356275303644,
      "grad_norm": 0.6592472195625305,
      "learning_rate": 2.5344129554655872e-05,
      "loss": 0.1102,
      "step": 2440
    },
    {
      "epoch": 2.4898785425101213,
      "grad_norm": 0.15306790173053741,
      "learning_rate": 2.51417004048583e-05,
      "loss": 0.0744,
      "step": 2460
    },
    {
      "epoch": 2.5101214574898787,
      "grad_norm": 0.874762237071991,
      "learning_rate": 2.493927125506073e-05,
      "loss": 0.0824,
      "step": 2480
    },
    {
      "epoch": 2.5303643724696356,
      "grad_norm": 0.45492422580718994,
      "learning_rate": 2.4736842105263158e-05,
      "loss": 0.0673,
      "step": 2500
    },
    {
      "epoch": 2.5506072874493926,
      "grad_norm": 1.1338578462600708,
      "learning_rate": 2.453441295546559e-05,
      "loss": 0.0814,
      "step": 2520
    },
    {
      "epoch": 2.57085020242915,
      "grad_norm": 2.3028781414031982,
      "learning_rate": 2.433198380566802e-05,
      "loss": 0.0793,
      "step": 2540
    },
    {
      "epoch": 2.591093117408907,
      "grad_norm": 0.5943863987922668,
      "learning_rate": 2.4129554655870446e-05,
      "loss": 0.0668,
      "step": 2560
    },
    {
      "epoch": 2.611336032388664,
      "grad_norm": 3.6341724395751953,
      "learning_rate": 2.3927125506072877e-05,
      "loss": 0.0856,
      "step": 2580
    },
    {
      "epoch": 2.6315789473684212,
      "grad_norm": 13.007461547851562,
      "learning_rate": 2.3724696356275304e-05,
      "loss": 0.0934,
      "step": 2600
    },
    {
      "epoch": 2.651821862348178,
      "grad_norm": 3.211059331893921,
      "learning_rate": 2.352226720647773e-05,
      "loss": 0.149,
      "step": 2620
    },
    {
      "epoch": 2.672064777327935,
      "grad_norm": 0.4208239018917084,
      "learning_rate": 2.3319838056680162e-05,
      "loss": 0.09,
      "step": 2640
    },
    {
      "epoch": 2.6923076923076925,
      "grad_norm": 0.48281416296958923,
      "learning_rate": 2.3117408906882593e-05,
      "loss": 0.0891,
      "step": 2660
    },
    {
      "epoch": 2.7125506072874495,
      "grad_norm": 1.9949498176574707,
      "learning_rate": 2.291497975708502e-05,
      "loss": 0.0704,
      "step": 2680
    },
    {
      "epoch": 2.7327935222672064,
      "grad_norm": 2.283033847808838,
      "learning_rate": 2.271255060728745e-05,
      "loss": 0.0697,
      "step": 2700
    },
    {
      "epoch": 2.753036437246964,
      "grad_norm": 4.5224690437316895,
      "learning_rate": 2.251012145748988e-05,
      "loss": 0.0716,
      "step": 2720
    },
    {
      "epoch": 2.7732793522267207,
      "grad_norm": 1.1362594366073608,
      "learning_rate": 2.230769230769231e-05,
      "loss": 0.0969,
      "step": 2740
    },
    {
      "epoch": 2.7935222672064777,
      "grad_norm": 4.973910808563232,
      "learning_rate": 2.2105263157894736e-05,
      "loss": 0.0831,
      "step": 2760
    },
    {
      "epoch": 2.813765182186235,
      "grad_norm": 3.1905055046081543,
      "learning_rate": 2.1902834008097167e-05,
      "loss": 0.0719,
      "step": 2780
    },
    {
      "epoch": 2.834008097165992,
      "grad_norm": 0.848556399345398,
      "learning_rate": 2.1700404858299598e-05,
      "loss": 0.1163,
      "step": 2800
    },
    {
      "epoch": 2.854251012145749,
      "grad_norm": 3.349083662033081,
      "learning_rate": 2.1497975708502025e-05,
      "loss": 0.1075,
      "step": 2820
    },
    {
      "epoch": 2.8744939271255063,
      "grad_norm": 2.1981165409088135,
      "learning_rate": 2.1295546558704455e-05,
      "loss": 0.0833,
      "step": 2840
    },
    {
      "epoch": 2.8947368421052633,
      "grad_norm": 1.8198034763336182,
      "learning_rate": 2.1093117408906886e-05,
      "loss": 0.0901,
      "step": 2860
    },
    {
      "epoch": 2.91497975708502,
      "grad_norm": 2.7684178352355957,
      "learning_rate": 2.089068825910931e-05,
      "loss": 0.0601,
      "step": 2880
    },
    {
      "epoch": 2.9352226720647776,
      "grad_norm": 3.5181796550750732,
      "learning_rate": 2.068825910931174e-05,
      "loss": 0.1002,
      "step": 2900
    },
    {
      "epoch": 2.9554655870445345,
      "grad_norm": 0.5474473834037781,
      "learning_rate": 2.048582995951417e-05,
      "loss": 0.0731,
      "step": 2920
    },
    {
      "epoch": 2.9757085020242915,
      "grad_norm": 1.101473093032837,
      "learning_rate": 2.02834008097166e-05,
      "loss": 0.0602,
      "step": 2940
    },
    {
      "epoch": 2.9959514170040484,
      "grad_norm": 7.263940811157227,
      "learning_rate": 2.008097165991903e-05,
      "loss": 0.1035,
      "step": 2960
    },
    {
      "epoch": 3.016194331983806,
      "grad_norm": 1.3408347368240356,
      "learning_rate": 1.987854251012146e-05,
      "loss": 0.0716,
      "step": 2980
    },
    {
      "epoch": 3.0364372469635628,
      "grad_norm": 2.9013640880584717,
      "learning_rate": 1.9676113360323887e-05,
      "loss": 0.0966,
      "step": 3000
    },
    {
      "epoch": 3.0566801619433197,
      "grad_norm": 1.4579267501831055,
      "learning_rate": 1.9473684210526315e-05,
      "loss": 0.0606,
      "step": 3020
    },
    {
      "epoch": 3.076923076923077,
      "grad_norm": 2.6459386348724365,
      "learning_rate": 1.9271255060728745e-05,
      "loss": 0.069,
      "step": 3040
    },
    {
      "epoch": 3.097165991902834,
      "grad_norm": 4.0359930992126465,
      "learning_rate": 1.9068825910931176e-05,
      "loss": 0.0717,
      "step": 3060
    },
    {
      "epoch": 3.117408906882591,
      "grad_norm": 6.0266432762146,
      "learning_rate": 1.8866396761133603e-05,
      "loss": 0.0851,
      "step": 3080
    },
    {
      "epoch": 3.1376518218623484,
      "grad_norm": 0.8523474335670471,
      "learning_rate": 1.8663967611336034e-05,
      "loss": 0.0951,
      "step": 3100
    },
    {
      "epoch": 3.1578947368421053,
      "grad_norm": 4.505618095397949,
      "learning_rate": 1.8461538461538465e-05,
      "loss": 0.0735,
      "step": 3120
    },
    {
      "epoch": 3.1781376518218623,
      "grad_norm": 1.400702714920044,
      "learning_rate": 1.8259109311740892e-05,
      "loss": 0.084,
      "step": 3140
    },
    {
      "epoch": 3.1983805668016196,
      "grad_norm": 1.4764870405197144,
      "learning_rate": 1.805668016194332e-05,
      "loss": 0.0542,
      "step": 3160
    },
    {
      "epoch": 3.2186234817813766,
      "grad_norm": 2.1480062007904053,
      "learning_rate": 1.785425101214575e-05,
      "loss": 0.0578,
      "step": 3180
    },
    {
      "epoch": 3.2388663967611335,
      "grad_norm": 1.5582636594772339,
      "learning_rate": 1.7651821862348177e-05,
      "loss": 0.0551,
      "step": 3200
    },
    {
      "epoch": 3.2591093117408905,
      "grad_norm": 1.1935584545135498,
      "learning_rate": 1.7449392712550608e-05,
      "loss": 0.088,
      "step": 3220
    },
    {
      "epoch": 3.279352226720648,
      "grad_norm": 0.8648160696029663,
      "learning_rate": 1.724696356275304e-05,
      "loss": 0.0992,
      "step": 3240
    },
    {
      "epoch": 3.299595141700405,
      "grad_norm": 0.9331728219985962,
      "learning_rate": 1.7044534412955466e-05,
      "loss": 0.0964,
      "step": 3260
    },
    {
      "epoch": 3.3198380566801617,
      "grad_norm": 0.5049517750740051,
      "learning_rate": 1.6842105263157896e-05,
      "loss": 0.065,
      "step": 3280
    },
    {
      "epoch": 3.340080971659919,
      "grad_norm": 1.2186537981033325,
      "learning_rate": 1.6639676113360324e-05,
      "loss": 0.0547,
      "step": 3300
    },
    {
      "epoch": 3.360323886639676,
      "grad_norm": 1.2250052690505981,
      "learning_rate": 1.6437246963562754e-05,
      "loss": 0.0523,
      "step": 3320
    },
    {
      "epoch": 3.380566801619433,
      "grad_norm": 1.378104329109192,
      "learning_rate": 1.6234817813765182e-05,
      "loss": 0.0651,
      "step": 3340
    },
    {
      "epoch": 3.4008097165991904,
      "grad_norm": 0.954174280166626,
      "learning_rate": 1.6032388663967612e-05,
      "loss": 0.0502,
      "step": 3360
    },
    {
      "epoch": 3.4210526315789473,
      "grad_norm": 0.7602891325950623,
      "learning_rate": 1.5829959514170043e-05,
      "loss": 0.0882,
      "step": 3380
    },
    {
      "epoch": 3.4412955465587043,
      "grad_norm": 4.254491329193115,
      "learning_rate": 1.562753036437247e-05,
      "loss": 0.0777,
      "step": 3400
    },
    {
      "epoch": 3.4615384615384617,
      "grad_norm": 0.797926127910614,
      "learning_rate": 1.54251012145749e-05,
      "loss": 0.0616,
      "step": 3420
    },
    {
      "epoch": 3.4817813765182186,
      "grad_norm": 2.5176289081573486,
      "learning_rate": 1.522267206477733e-05,
      "loss": 0.0824,
      "step": 3440
    },
    {
      "epoch": 3.5020242914979756,
      "grad_norm": 1.0014945268630981,
      "learning_rate": 1.5020242914979757e-05,
      "loss": 0.0654,
      "step": 3460
    },
    {
      "epoch": 3.522267206477733,
      "grad_norm": 6.709611892700195,
      "learning_rate": 1.4817813765182186e-05,
      "loss": 0.1014,
      "step": 3480
    },
    {
      "epoch": 3.54251012145749,
      "grad_norm": 2.213196039199829,
      "learning_rate": 1.4615384615384617e-05,
      "loss": 0.0575,
      "step": 3500
    },
    {
      "epoch": 3.562753036437247,
      "grad_norm": 1.0327197313308716,
      "learning_rate": 1.4412955465587044e-05,
      "loss": 0.0581,
      "step": 3520
    },
    {
      "epoch": 3.582995951417004,
      "grad_norm": 3.932582378387451,
      "learning_rate": 1.4210526315789475e-05,
      "loss": 0.0818,
      "step": 3540
    },
    {
      "epoch": 3.603238866396761,
      "grad_norm": 0.2910901606082916,
      "learning_rate": 1.4008097165991904e-05,
      "loss": 0.0618,
      "step": 3560
    },
    {
      "epoch": 3.623481781376518,
      "grad_norm": 1.6906574964523315,
      "learning_rate": 1.3805668016194331e-05,
      "loss": 0.0486,
      "step": 3580
    },
    {
      "epoch": 3.6437246963562755,
      "grad_norm": 0.9147934317588806,
      "learning_rate": 1.3603238866396762e-05,
      "loss": 0.08,
      "step": 3600
    },
    {
      "epoch": 3.6639676113360324,
      "grad_norm": 3.8570754528045654,
      "learning_rate": 1.3400809716599191e-05,
      "loss": 0.0674,
      "step": 3620
    },
    {
      "epoch": 3.6842105263157894,
      "grad_norm": 3.0517051219940186,
      "learning_rate": 1.3198380566801622e-05,
      "loss": 0.0676,
      "step": 3640
    },
    {
      "epoch": 3.7044534412955468,
      "grad_norm": 1.3758320808410645,
      "learning_rate": 1.2995951417004049e-05,
      "loss": 0.0561,
      "step": 3660
    },
    {
      "epoch": 3.7246963562753037,
      "grad_norm": 0.43304064869880676,
      "learning_rate": 1.2793522267206478e-05,
      "loss": 0.0635,
      "step": 3680
    },
    {
      "epoch": 3.7449392712550607,
      "grad_norm": 1.5206581354141235,
      "learning_rate": 1.2591093117408908e-05,
      "loss": 0.0547,
      "step": 3700
    },
    {
      "epoch": 3.765182186234818,
      "grad_norm": 3.9041523933410645,
      "learning_rate": 1.2388663967611337e-05,
      "loss": 0.0638,
      "step": 3720
    },
    {
      "epoch": 3.785425101214575,
      "grad_norm": 13.362547874450684,
      "learning_rate": 1.2186234817813766e-05,
      "loss": 0.0723,
      "step": 3740
    },
    {
      "epoch": 3.805668016194332,
      "grad_norm": 9.504450798034668,
      "learning_rate": 1.1983805668016194e-05,
      "loss": 0.0567,
      "step": 3760
    },
    {
      "epoch": 3.8259109311740893,
      "grad_norm": 2.393489122390747,
      "learning_rate": 1.1781376518218624e-05,
      "loss": 0.1019,
      "step": 3780
    },
    {
      "epoch": 3.8461538461538463,
      "grad_norm": 3.6273298263549805,
      "learning_rate": 1.1578947368421053e-05,
      "loss": 0.078,
      "step": 3800
    },
    {
      "epoch": 3.866396761133603,
      "grad_norm": 2.2987825870513916,
      "learning_rate": 1.1376518218623482e-05,
      "loss": 0.0964,
      "step": 3820
    },
    {
      "epoch": 3.8866396761133606,
      "grad_norm": 0.31518688797950745,
      "learning_rate": 1.1174089068825911e-05,
      "loss": 0.0827,
      "step": 3840
    },
    {
      "epoch": 3.9068825910931175,
      "grad_norm": 11.653219223022461,
      "learning_rate": 1.097165991902834e-05,
      "loss": 0.1376,
      "step": 3860
    },
    {
      "epoch": 3.9271255060728745,
      "grad_norm": 1.3333994150161743,
      "learning_rate": 1.0769230769230771e-05,
      "loss": 0.0941,
      "step": 3880
    },
    {
      "epoch": 3.9473684210526314,
      "grad_norm": 0.2724575698375702,
      "learning_rate": 1.0566801619433198e-05,
      "loss": 0.0639,
      "step": 3900
    },
    {
      "epoch": 3.967611336032389,
      "grad_norm": 4.785472393035889,
      "learning_rate": 1.0364372469635627e-05,
      "loss": 0.0784,
      "step": 3920
    },
    {
      "epoch": 3.9878542510121457,
      "grad_norm": 5.476631164550781,
      "learning_rate": 1.0161943319838058e-05,
      "loss": 0.0578,
      "step": 3940
    },
    {
      "epoch": 4.008097165991903,
      "grad_norm": 0.9696636199951172,
      "learning_rate": 9.959514170040487e-06,
      "loss": 0.0778,
      "step": 3960
    },
    {
      "epoch": 4.02834008097166,
      "grad_norm": 0.6126569509506226,
      "learning_rate": 9.757085020242914e-06,
      "loss": 0.0968,
      "step": 3980
    },
    {
      "epoch": 4.048582995951417,
      "grad_norm": 4.200432777404785,
      "learning_rate": 9.554655870445345e-06,
      "loss": 0.0611,
      "step": 4000
    }
  ],
  "logging_steps": 20,
  "max_steps": 4940,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.4015353235020186e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
