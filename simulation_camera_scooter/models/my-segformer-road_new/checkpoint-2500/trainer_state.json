{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.5303643724696356,
  "eval_steps": 500,
  "global_step": 2500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.020242914979757085,
      "grad_norm": 2.60353684425354,
      "learning_rate": 4.980769230769231e-05,
      "loss": 0.5543,
      "step": 20
    },
    {
      "epoch": 0.04048582995951417,
      "grad_norm": 1.4951989650726318,
      "learning_rate": 4.960526315789474e-05,
      "loss": 0.3538,
      "step": 40
    },
    {
      "epoch": 0.06072874493927125,
      "grad_norm": 1.2178782224655151,
      "learning_rate": 4.940283400809717e-05,
      "loss": 0.2834,
      "step": 60
    },
    {
      "epoch": 0.08097165991902834,
      "grad_norm": 1.408525824546814,
      "learning_rate": 4.92004048582996e-05,
      "loss": 0.2507,
      "step": 80
    },
    {
      "epoch": 0.10121457489878542,
      "grad_norm": 2.4710991382598877,
      "learning_rate": 4.899797570850202e-05,
      "loss": 0.232,
      "step": 100
    },
    {
      "epoch": 0.1214574898785425,
      "grad_norm": 1.517261028289795,
      "learning_rate": 4.879554655870446e-05,
      "loss": 0.1583,
      "step": 120
    },
    {
      "epoch": 0.1417004048582996,
      "grad_norm": 2.8705952167510986,
      "learning_rate": 4.8603238866396764e-05,
      "loss": 0.2336,
      "step": 140
    },
    {
      "epoch": 0.16194331983805668,
      "grad_norm": 2.681584358215332,
      "learning_rate": 4.8400809716599195e-05,
      "loss": 0.1664,
      "step": 160
    },
    {
      "epoch": 0.18218623481781376,
      "grad_norm": 1.6810041666030884,
      "learning_rate": 4.819838056680162e-05,
      "loss": 0.2291,
      "step": 180
    },
    {
      "epoch": 0.20242914979757085,
      "grad_norm": 2.6532223224639893,
      "learning_rate": 4.7995951417004056e-05,
      "loss": 0.1705,
      "step": 200
    },
    {
      "epoch": 0.22267206477732793,
      "grad_norm": 2.7997703552246094,
      "learning_rate": 4.779352226720648e-05,
      "loss": 0.151,
      "step": 220
    },
    {
      "epoch": 0.242914979757085,
      "grad_norm": 4.134150981903076,
      "learning_rate": 4.759109311740891e-05,
      "loss": 0.1737,
      "step": 240
    },
    {
      "epoch": 0.2631578947368421,
      "grad_norm": 6.276228427886963,
      "learning_rate": 4.738866396761134e-05,
      "loss": 0.1654,
      "step": 260
    },
    {
      "epoch": 0.2834008097165992,
      "grad_norm": 1.7194103002548218,
      "learning_rate": 4.7186234817813765e-05,
      "loss": 0.1279,
      "step": 280
    },
    {
      "epoch": 0.30364372469635625,
      "grad_norm": 3.241950511932373,
      "learning_rate": 4.6983805668016196e-05,
      "loss": 0.1641,
      "step": 300
    },
    {
      "epoch": 0.32388663967611336,
      "grad_norm": 9.388757705688477,
      "learning_rate": 4.6781376518218626e-05,
      "loss": 0.2066,
      "step": 320
    },
    {
      "epoch": 0.3441295546558704,
      "grad_norm": 0.6280366778373718,
      "learning_rate": 4.658906882591093e-05,
      "loss": 0.1364,
      "step": 340
    },
    {
      "epoch": 0.3643724696356275,
      "grad_norm": 4.365753650665283,
      "learning_rate": 4.638663967611336e-05,
      "loss": 0.1371,
      "step": 360
    },
    {
      "epoch": 0.38461538461538464,
      "grad_norm": 8.496685028076172,
      "learning_rate": 4.618421052631579e-05,
      "loss": 0.1191,
      "step": 380
    },
    {
      "epoch": 0.4048582995951417,
      "grad_norm": 8.699529647827148,
      "learning_rate": 4.5981781376518216e-05,
      "loss": 0.1495,
      "step": 400
    },
    {
      "epoch": 0.4251012145748988,
      "grad_norm": 5.345395565032959,
      "learning_rate": 4.577935222672065e-05,
      "loss": 0.1394,
      "step": 420
    },
    {
      "epoch": 0.44534412955465585,
      "grad_norm": 4.354844570159912,
      "learning_rate": 4.557692307692308e-05,
      "loss": 0.1314,
      "step": 440
    },
    {
      "epoch": 0.46558704453441296,
      "grad_norm": 7.832252025604248,
      "learning_rate": 4.537449392712551e-05,
      "loss": 0.1813,
      "step": 460
    },
    {
      "epoch": 0.48582995951417,
      "grad_norm": 0.4733159840106964,
      "learning_rate": 4.517206477732794e-05,
      "loss": 0.1474,
      "step": 480
    },
    {
      "epoch": 0.5060728744939271,
      "grad_norm": 4.4916768074035645,
      "learning_rate": 4.496963562753036e-05,
      "loss": 0.1178,
      "step": 500
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 6.250394344329834,
      "learning_rate": 4.47672064777328e-05,
      "loss": 0.1279,
      "step": 520
    },
    {
      "epoch": 0.5465587044534413,
      "grad_norm": 1.0069736242294312,
      "learning_rate": 4.4564777327935224e-05,
      "loss": 0.127,
      "step": 540
    },
    {
      "epoch": 0.5668016194331984,
      "grad_norm": 2.2202513217926025,
      "learning_rate": 4.4362348178137654e-05,
      "loss": 0.1244,
      "step": 560
    },
    {
      "epoch": 0.5870445344129555,
      "grad_norm": 2.029829978942871,
      "learning_rate": 4.4159919028340085e-05,
      "loss": 0.1545,
      "step": 580
    },
    {
      "epoch": 0.6072874493927125,
      "grad_norm": 1.6138578653335571,
      "learning_rate": 4.3957489878542516e-05,
      "loss": 0.1674,
      "step": 600
    },
    {
      "epoch": 0.6275303643724697,
      "grad_norm": 3.7324604988098145,
      "learning_rate": 4.375506072874494e-05,
      "loss": 0.1436,
      "step": 620
    },
    {
      "epoch": 0.6477732793522267,
      "grad_norm": 4.236327648162842,
      "learning_rate": 4.356275303643725e-05,
      "loss": 0.1317,
      "step": 640
    },
    {
      "epoch": 0.6680161943319838,
      "grad_norm": 11.883174896240234,
      "learning_rate": 4.3360323886639674e-05,
      "loss": 0.1609,
      "step": 660
    },
    {
      "epoch": 0.6882591093117408,
      "grad_norm": 1.322102665901184,
      "learning_rate": 4.3157894736842105e-05,
      "loss": 0.1057,
      "step": 680
    },
    {
      "epoch": 0.708502024291498,
      "grad_norm": 3.9290645122528076,
      "learning_rate": 4.2955465587044536e-05,
      "loss": 0.1542,
      "step": 700
    },
    {
      "epoch": 0.728744939271255,
      "grad_norm": 2.389382839202881,
      "learning_rate": 4.2753036437246966e-05,
      "loss": 0.1145,
      "step": 720
    },
    {
      "epoch": 0.7489878542510121,
      "grad_norm": 0.7864636778831482,
      "learning_rate": 4.25506072874494e-05,
      "loss": 0.0963,
      "step": 740
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 1.3286188840866089,
      "learning_rate": 4.234817813765182e-05,
      "loss": 0.1284,
      "step": 760
    },
    {
      "epoch": 0.7894736842105263,
      "grad_norm": 7.57919454574585,
      "learning_rate": 4.214574898785426e-05,
      "loss": 0.1308,
      "step": 780
    },
    {
      "epoch": 0.8097165991902834,
      "grad_norm": 5.662615776062012,
      "learning_rate": 4.194331983805668e-05,
      "loss": 0.1644,
      "step": 800
    },
    {
      "epoch": 0.8299595141700404,
      "grad_norm": 6.5239410400390625,
      "learning_rate": 4.174089068825911e-05,
      "loss": 0.1093,
      "step": 820
    },
    {
      "epoch": 0.8502024291497976,
      "grad_norm": 0.7537091970443726,
      "learning_rate": 4.1538461538461544e-05,
      "loss": 0.1293,
      "step": 840
    },
    {
      "epoch": 0.8704453441295547,
      "grad_norm": 1.4398534297943115,
      "learning_rate": 4.133603238866397e-05,
      "loss": 0.1366,
      "step": 860
    },
    {
      "epoch": 0.8906882591093117,
      "grad_norm": 1.0573694705963135,
      "learning_rate": 4.11336032388664e-05,
      "loss": 0.1181,
      "step": 880
    },
    {
      "epoch": 0.9109311740890689,
      "grad_norm": 1.6042877435684204,
      "learning_rate": 4.093117408906883e-05,
      "loss": 0.1556,
      "step": 900
    },
    {
      "epoch": 0.9311740890688259,
      "grad_norm": 1.6729271411895752,
      "learning_rate": 4.072874493927126e-05,
      "loss": 0.0979,
      "step": 920
    },
    {
      "epoch": 0.951417004048583,
      "grad_norm": 1.523969054222107,
      "learning_rate": 4.0526315789473684e-05,
      "loss": 0.1277,
      "step": 940
    },
    {
      "epoch": 0.97165991902834,
      "grad_norm": 5.040785312652588,
      "learning_rate": 4.0323886639676114e-05,
      "loss": 0.1036,
      "step": 960
    },
    {
      "epoch": 0.9919028340080972,
      "grad_norm": 2.866434097290039,
      "learning_rate": 4.0121457489878545e-05,
      "loss": 0.1359,
      "step": 980
    },
    {
      "epoch": 1.0121457489878543,
      "grad_norm": 3.0122830867767334,
      "learning_rate": 3.991902834008097e-05,
      "loss": 0.1335,
      "step": 1000
    },
    {
      "epoch": 1.0323886639676114,
      "grad_norm": 0.7991473078727722,
      "learning_rate": 3.9716599190283406e-05,
      "loss": 0.1215,
      "step": 1020
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 1.5124045610427856,
      "learning_rate": 3.951417004048583e-05,
      "loss": 0.0833,
      "step": 1040
    },
    {
      "epoch": 1.0728744939271255,
      "grad_norm": 0.8686792254447937,
      "learning_rate": 3.931174089068826e-05,
      "loss": 0.0868,
      "step": 1060
    },
    {
      "epoch": 1.0931174089068827,
      "grad_norm": 0.6204802989959717,
      "learning_rate": 3.910931174089069e-05,
      "loss": 0.1123,
      "step": 1080
    },
    {
      "epoch": 1.1133603238866396,
      "grad_norm": 1.5977180004119873,
      "learning_rate": 3.890688259109312e-05,
      "loss": 0.0891,
      "step": 1100
    },
    {
      "epoch": 1.1336032388663968,
      "grad_norm": 1.9436721801757812,
      "learning_rate": 3.8704453441295546e-05,
      "loss": 0.0985,
      "step": 1120
    },
    {
      "epoch": 1.1538461538461537,
      "grad_norm": 1.1701987981796265,
      "learning_rate": 3.850202429149798e-05,
      "loss": 0.1505,
      "step": 1140
    },
    {
      "epoch": 1.174089068825911,
      "grad_norm": 17.12029266357422,
      "learning_rate": 3.829959514170041e-05,
      "loss": 0.1285,
      "step": 1160
    },
    {
      "epoch": 1.194331983805668,
      "grad_norm": 8.780117988586426,
      "learning_rate": 3.809716599190283e-05,
      "loss": 0.1086,
      "step": 1180
    },
    {
      "epoch": 1.214574898785425,
      "grad_norm": 0.9133884310722351,
      "learning_rate": 3.789473684210527e-05,
      "loss": 0.1054,
      "step": 1200
    },
    {
      "epoch": 1.2348178137651822,
      "grad_norm": 0.4866701662540436,
      "learning_rate": 3.769230769230769e-05,
      "loss": 0.0641,
      "step": 1220
    },
    {
      "epoch": 1.2550607287449393,
      "grad_norm": 0.8039166927337646,
      "learning_rate": 3.748987854251012e-05,
      "loss": 0.1268,
      "step": 1240
    },
    {
      "epoch": 1.2753036437246963,
      "grad_norm": 5.949751377105713,
      "learning_rate": 3.7287449392712554e-05,
      "loss": 0.1019,
      "step": 1260
    },
    {
      "epoch": 1.2955465587044535,
      "grad_norm": 0.2436349242925644,
      "learning_rate": 3.708502024291498e-05,
      "loss": 0.1134,
      "step": 1280
    },
    {
      "epoch": 1.3157894736842106,
      "grad_norm": 0.3876831531524658,
      "learning_rate": 3.688259109311741e-05,
      "loss": 0.0828,
      "step": 1300
    },
    {
      "epoch": 1.3360323886639676,
      "grad_norm": 1.0606331825256348,
      "learning_rate": 3.668016194331984e-05,
      "loss": 0.0899,
      "step": 1320
    },
    {
      "epoch": 1.3562753036437247,
      "grad_norm": 1.8161728382110596,
      "learning_rate": 3.647773279352227e-05,
      "loss": 0.1133,
      "step": 1340
    },
    {
      "epoch": 1.376518218623482,
      "grad_norm": 2.027841329574585,
      "learning_rate": 3.62753036437247e-05,
      "loss": 0.0958,
      "step": 1360
    },
    {
      "epoch": 1.3967611336032388,
      "grad_norm": 2.5625786781311035,
      "learning_rate": 3.607287449392713e-05,
      "loss": 0.0848,
      "step": 1380
    },
    {
      "epoch": 1.417004048582996,
      "grad_norm": 1.9966802597045898,
      "learning_rate": 3.5870445344129555e-05,
      "loss": 0.086,
      "step": 1400
    },
    {
      "epoch": 1.4372469635627532,
      "grad_norm": 2.6053574085235596,
      "learning_rate": 3.5668016194331986e-05,
      "loss": 0.095,
      "step": 1420
    },
    {
      "epoch": 1.45748987854251,
      "grad_norm": 0.972520649433136,
      "learning_rate": 3.5465587044534417e-05,
      "loss": 0.1108,
      "step": 1440
    },
    {
      "epoch": 1.4777327935222673,
      "grad_norm": 1.3663145303726196,
      "learning_rate": 3.526315789473684e-05,
      "loss": 0.1069,
      "step": 1460
    },
    {
      "epoch": 1.4979757085020242,
      "grad_norm": 1.9777629375457764,
      "learning_rate": 3.506072874493928e-05,
      "loss": 0.1227,
      "step": 1480
    },
    {
      "epoch": 1.5182186234817814,
      "grad_norm": 0.5192674398422241,
      "learning_rate": 3.48582995951417e-05,
      "loss": 0.0995,
      "step": 1500
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 3.5324535369873047,
      "learning_rate": 3.465587044534413e-05,
      "loss": 0.1126,
      "step": 1520
    },
    {
      "epoch": 1.5587044534412957,
      "grad_norm": 2.2765111923217773,
      "learning_rate": 3.445344129554656e-05,
      "loss": 0.1104,
      "step": 1540
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 4.693960189819336,
      "learning_rate": 3.425101214574899e-05,
      "loss": 0.0947,
      "step": 1560
    },
    {
      "epoch": 1.5991902834008096,
      "grad_norm": 1.0367261171340942,
      "learning_rate": 3.404858299595142e-05,
      "loss": 0.0972,
      "step": 1580
    },
    {
      "epoch": 1.6194331983805668,
      "grad_norm": 4.909794330596924,
      "learning_rate": 3.384615384615385e-05,
      "loss": 0.1032,
      "step": 1600
    },
    {
      "epoch": 1.639676113360324,
      "grad_norm": 4.734772205352783,
      "learning_rate": 3.364372469635628e-05,
      "loss": 0.0913,
      "step": 1620
    },
    {
      "epoch": 1.6599190283400809,
      "grad_norm": 1.2564631700515747,
      "learning_rate": 3.34412955465587e-05,
      "loss": 0.0947,
      "step": 1640
    },
    {
      "epoch": 1.680161943319838,
      "grad_norm": 2.455995559692383,
      "learning_rate": 3.3238866396761134e-05,
      "loss": 0.1341,
      "step": 1660
    },
    {
      "epoch": 1.7004048582995952,
      "grad_norm": 3.4936025142669678,
      "learning_rate": 3.3036437246963564e-05,
      "loss": 0.102,
      "step": 1680
    },
    {
      "epoch": 1.7206477732793521,
      "grad_norm": 5.708625316619873,
      "learning_rate": 3.283400809716599e-05,
      "loss": 0.1311,
      "step": 1700
    },
    {
      "epoch": 1.7408906882591093,
      "grad_norm": 8.04496955871582,
      "learning_rate": 3.2631578947368426e-05,
      "loss": 0.0973,
      "step": 1720
    },
    {
      "epoch": 1.7611336032388665,
      "grad_norm": 0.42990007996559143,
      "learning_rate": 3.242914979757085e-05,
      "loss": 0.0778,
      "step": 1740
    },
    {
      "epoch": 1.7813765182186234,
      "grad_norm": 0.5142814517021179,
      "learning_rate": 3.222672064777328e-05,
      "loss": 0.0835,
      "step": 1760
    },
    {
      "epoch": 1.8016194331983806,
      "grad_norm": 3.7256152629852295,
      "learning_rate": 3.202429149797571e-05,
      "loss": 0.1264,
      "step": 1780
    },
    {
      "epoch": 1.8218623481781377,
      "grad_norm": 2.2061614990234375,
      "learning_rate": 3.182186234817814e-05,
      "loss": 0.0866,
      "step": 1800
    },
    {
      "epoch": 1.8421052631578947,
      "grad_norm": 9.812321662902832,
      "learning_rate": 3.1619433198380566e-05,
      "loss": 0.1289,
      "step": 1820
    },
    {
      "epoch": 1.8623481781376519,
      "grad_norm": 4.329840660095215,
      "learning_rate": 3.1417004048582996e-05,
      "loss": 0.1401,
      "step": 1840
    },
    {
      "epoch": 1.882591093117409,
      "grad_norm": 3.1781063079833984,
      "learning_rate": 3.121457489878543e-05,
      "loss": 0.1147,
      "step": 1860
    },
    {
      "epoch": 1.902834008097166,
      "grad_norm": 4.145416259765625,
      "learning_rate": 3.101214574898785e-05,
      "loss": 0.0707,
      "step": 1880
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 4.064936637878418,
      "learning_rate": 3.080971659919029e-05,
      "loss": 0.0941,
      "step": 1900
    },
    {
      "epoch": 1.9433198380566803,
      "grad_norm": 0.2696869969367981,
      "learning_rate": 3.060728744939271e-05,
      "loss": 0.074,
      "step": 1920
    },
    {
      "epoch": 1.9635627530364372,
      "grad_norm": 7.998841285705566,
      "learning_rate": 3.0404858299595146e-05,
      "loss": 0.0917,
      "step": 1940
    },
    {
      "epoch": 1.9838056680161942,
      "grad_norm": 34.24335861206055,
      "learning_rate": 3.0202429149797573e-05,
      "loss": 0.1226,
      "step": 1960
    },
    {
      "epoch": 2.0040485829959516,
      "grad_norm": 0.6935098171234131,
      "learning_rate": 3e-05,
      "loss": 0.0893,
      "step": 1980
    },
    {
      "epoch": 2.0242914979757085,
      "grad_norm": 1.8242509365081787,
      "learning_rate": 2.979757085020243e-05,
      "loss": 0.0472,
      "step": 2000
    },
    {
      "epoch": 2.0445344129554655,
      "grad_norm": 1.7249743938446045,
      "learning_rate": 2.959514170040486e-05,
      "loss": 0.1042,
      "step": 2020
    },
    {
      "epoch": 2.064777327935223,
      "grad_norm": 1.1615363359451294,
      "learning_rate": 2.9392712550607286e-05,
      "loss": 0.1078,
      "step": 2040
    },
    {
      "epoch": 2.08502024291498,
      "grad_norm": 0.46546974778175354,
      "learning_rate": 2.919028340080972e-05,
      "loss": 0.0737,
      "step": 2060
    },
    {
      "epoch": 2.1052631578947367,
      "grad_norm": 0.5528144836425781,
      "learning_rate": 2.8987854251012147e-05,
      "loss": 0.1014,
      "step": 2080
    },
    {
      "epoch": 2.125506072874494,
      "grad_norm": 10.286727905273438,
      "learning_rate": 2.8785425101214575e-05,
      "loss": 0.0898,
      "step": 2100
    },
    {
      "epoch": 2.145748987854251,
      "grad_norm": 1.3573384284973145,
      "learning_rate": 2.858299595141701e-05,
      "loss": 0.0889,
      "step": 2120
    },
    {
      "epoch": 2.165991902834008,
      "grad_norm": 1.112186312675476,
      "learning_rate": 2.8380566801619436e-05,
      "loss": 0.0787,
      "step": 2140
    },
    {
      "epoch": 2.1862348178137654,
      "grad_norm": 2.859551191329956,
      "learning_rate": 2.8178137651821863e-05,
      "loss": 0.0802,
      "step": 2160
    },
    {
      "epoch": 2.2064777327935223,
      "grad_norm": 0.6965360045433044,
      "learning_rate": 2.7975708502024294e-05,
      "loss": 0.0755,
      "step": 2180
    },
    {
      "epoch": 2.2267206477732793,
      "grad_norm": 2.935131549835205,
      "learning_rate": 2.777327935222672e-05,
      "loss": 0.071,
      "step": 2200
    },
    {
      "epoch": 2.246963562753036,
      "grad_norm": 9.088553428649902,
      "learning_rate": 2.757085020242915e-05,
      "loss": 0.0619,
      "step": 2220
    },
    {
      "epoch": 2.2672064777327936,
      "grad_norm": 0.5289122462272644,
      "learning_rate": 2.7368421052631583e-05,
      "loss": 0.0839,
      "step": 2240
    },
    {
      "epoch": 2.2874493927125505,
      "grad_norm": 0.3528498411178589,
      "learning_rate": 2.716599190283401e-05,
      "loss": 0.0816,
      "step": 2260
    },
    {
      "epoch": 2.3076923076923075,
      "grad_norm": 1.907210111618042,
      "learning_rate": 2.6963562753036437e-05,
      "loss": 0.0671,
      "step": 2280
    },
    {
      "epoch": 2.327935222672065,
      "grad_norm": 2.901934862136841,
      "learning_rate": 2.6761133603238868e-05,
      "loss": 0.0761,
      "step": 2300
    },
    {
      "epoch": 2.348178137651822,
      "grad_norm": 1.4834688901901245,
      "learning_rate": 2.6558704453441295e-05,
      "loss": 0.0839,
      "step": 2320
    },
    {
      "epoch": 2.3684210526315788,
      "grad_norm": 1.0534882545471191,
      "learning_rate": 2.6356275303643722e-05,
      "loss": 0.1038,
      "step": 2340
    },
    {
      "epoch": 2.388663967611336,
      "grad_norm": 0.512983500957489,
      "learning_rate": 2.6153846153846157e-05,
      "loss": 0.0918,
      "step": 2360
    },
    {
      "epoch": 2.408906882591093,
      "grad_norm": 3.5520126819610596,
      "learning_rate": 2.5951417004048584e-05,
      "loss": 0.0801,
      "step": 2380
    },
    {
      "epoch": 2.42914979757085,
      "grad_norm": 7.9033002853393555,
      "learning_rate": 2.574898785425101e-05,
      "loss": 0.102,
      "step": 2400
    },
    {
      "epoch": 2.4493927125506074,
      "grad_norm": 3.79817271232605,
      "learning_rate": 2.5546558704453445e-05,
      "loss": 0.0677,
      "step": 2420
    },
    {
      "epoch": 2.4696356275303644,
      "grad_norm": 0.6592472195625305,
      "learning_rate": 2.5344129554655872e-05,
      "loss": 0.1102,
      "step": 2440
    },
    {
      "epoch": 2.4898785425101213,
      "grad_norm": 0.15306790173053741,
      "learning_rate": 2.51417004048583e-05,
      "loss": 0.0744,
      "step": 2460
    },
    {
      "epoch": 2.5101214574898787,
      "grad_norm": 0.874762237071991,
      "learning_rate": 2.493927125506073e-05,
      "loss": 0.0824,
      "step": 2480
    },
    {
      "epoch": 2.5303643724696356,
      "grad_norm": 0.45492422580718994,
      "learning_rate": 2.4736842105263158e-05,
      "loss": 0.0673,
      "step": 2500
    }
  ],
  "logging_steps": 20,
  "max_steps": 4940,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8.760472169663693e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
