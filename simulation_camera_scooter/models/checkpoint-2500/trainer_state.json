{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.2532158411830244,
  "eval_steps": 500,
  "global_step": 2500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0020257267294641955,
      "grad_norm": 2.4405038356781006,
      "learning_rate": 4.998075559607009e-05,
      "loss": 0.5615,
      "step": 20
    },
    {
      "epoch": 0.004051453458928391,
      "grad_norm": 1.4659157991409302,
      "learning_rate": 4.996049832877545e-05,
      "loss": 0.3374,
      "step": 40
    },
    {
      "epoch": 0.006077180188392586,
      "grad_norm": 1.5483160018920898,
      "learning_rate": 4.994024106148081e-05,
      "loss": 0.2433,
      "step": 60
    },
    {
      "epoch": 0.008102906917856782,
      "grad_norm": 2.1053307056427,
      "learning_rate": 4.9919983794186165e-05,
      "loss": 0.2178,
      "step": 80
    },
    {
      "epoch": 0.010128633647320976,
      "grad_norm": 0.9805480241775513,
      "learning_rate": 4.989972652689153e-05,
      "loss": 0.2048,
      "step": 100
    },
    {
      "epoch": 0.012154360376785172,
      "grad_norm": 2.8173420429229736,
      "learning_rate": 4.987946925959689e-05,
      "loss": 0.1792,
      "step": 120
    },
    {
      "epoch": 0.014180087106249366,
      "grad_norm": 3.2427754402160645,
      "learning_rate": 4.985921199230224e-05,
      "loss": 0.1567,
      "step": 140
    },
    {
      "epoch": 0.016205813835713564,
      "grad_norm": 1.0643627643585205,
      "learning_rate": 4.9838954725007595e-05,
      "loss": 0.1468,
      "step": 160
    },
    {
      "epoch": 0.018231540565177756,
      "grad_norm": 2.5849173069000244,
      "learning_rate": 4.981971032107769e-05,
      "loss": 0.1942,
      "step": 180
    },
    {
      "epoch": 0.020257267294641952,
      "grad_norm": 13.793347358703613,
      "learning_rate": 4.979945305378305e-05,
      "loss": 0.1739,
      "step": 200
    },
    {
      "epoch": 0.022282994024106148,
      "grad_norm": 1.154039978981018,
      "learning_rate": 4.97791957864884e-05,
      "loss": 0.1475,
      "step": 220
    },
    {
      "epoch": 0.024308720753570344,
      "grad_norm": 1.3792349100112915,
      "learning_rate": 4.9758938519193764e-05,
      "loss": 0.1279,
      "step": 240
    },
    {
      "epoch": 0.02633444748303454,
      "grad_norm": 1.2435647249221802,
      "learning_rate": 4.973868125189912e-05,
      "loss": 0.1234,
      "step": 260
    },
    {
      "epoch": 0.028360174212498732,
      "grad_norm": 0.7834601402282715,
      "learning_rate": 4.971842398460448e-05,
      "loss": 0.1422,
      "step": 280
    },
    {
      "epoch": 0.030385900941962928,
      "grad_norm": 0.8932020664215088,
      "learning_rate": 4.9698166717309836e-05,
      "loss": 0.1231,
      "step": 300
    },
    {
      "epoch": 0.03241162767142713,
      "grad_norm": 1.0319157838821411,
      "learning_rate": 4.96779094500152e-05,
      "loss": 0.1448,
      "step": 320
    },
    {
      "epoch": 0.03443735440089132,
      "grad_norm": 0.9127151966094971,
      "learning_rate": 4.965765218272056e-05,
      "loss": 0.1259,
      "step": 340
    },
    {
      "epoch": 0.03646308113035551,
      "grad_norm": 1.1230705976486206,
      "learning_rate": 4.963739491542591e-05,
      "loss": 0.1174,
      "step": 360
    },
    {
      "epoch": 0.03848880785981971,
      "grad_norm": 4.197830677032471,
      "learning_rate": 4.9617137648131265e-05,
      "loss": 0.1239,
      "step": 380
    },
    {
      "epoch": 0.040514534589283904,
      "grad_norm": 0.9139384627342224,
      "learning_rate": 4.959688038083663e-05,
      "loss": 0.1511,
      "step": 400
    },
    {
      "epoch": 0.0425402613187481,
      "grad_norm": 1.3449727296829224,
      "learning_rate": 4.957662311354199e-05,
      "loss": 0.1322,
      "step": 420
    },
    {
      "epoch": 0.044565988048212296,
      "grad_norm": 3.993757724761963,
      "learning_rate": 4.9556365846247344e-05,
      "loss": 0.1058,
      "step": 440
    },
    {
      "epoch": 0.04659171477767649,
      "grad_norm": 4.853125095367432,
      "learning_rate": 4.95361085789527e-05,
      "loss": 0.1022,
      "step": 460
    },
    {
      "epoch": 0.04861744150714069,
      "grad_norm": 1.7318204641342163,
      "learning_rate": 4.9515851311658066e-05,
      "loss": 0.126,
      "step": 480
    },
    {
      "epoch": 0.050643168236604884,
      "grad_norm": 2.970012664794922,
      "learning_rate": 4.9495594044363416e-05,
      "loss": 0.1009,
      "step": 500
    },
    {
      "epoch": 0.05266889496606908,
      "grad_norm": 2.0667383670806885,
      "learning_rate": 4.9475336777068773e-05,
      "loss": 0.1033,
      "step": 520
    },
    {
      "epoch": 0.054694621695533276,
      "grad_norm": 1.1282299757003784,
      "learning_rate": 4.945507950977413e-05,
      "loss": 0.0934,
      "step": 540
    },
    {
      "epoch": 0.056720348424997465,
      "grad_norm": 2.0177979469299316,
      "learning_rate": 4.943482224247949e-05,
      "loss": 0.1238,
      "step": 560
    },
    {
      "epoch": 0.05874607515446166,
      "grad_norm": 1.2376540899276733,
      "learning_rate": 4.941456497518485e-05,
      "loss": 0.0871,
      "step": 580
    },
    {
      "epoch": 0.060771801883925856,
      "grad_norm": 2.9011895656585693,
      "learning_rate": 4.939430770789021e-05,
      "loss": 0.1128,
      "step": 600
    },
    {
      "epoch": 0.06279752861339005,
      "grad_norm": 1.1684095859527588,
      "learning_rate": 4.937405044059557e-05,
      "loss": 0.1189,
      "step": 620
    },
    {
      "epoch": 0.06482325534285426,
      "grad_norm": 0.638354480266571,
      "learning_rate": 4.9353793173300924e-05,
      "loss": 0.1053,
      "step": 640
    },
    {
      "epoch": 0.06684898207231844,
      "grad_norm": 2.9932680130004883,
      "learning_rate": 4.933353590600628e-05,
      "loss": 0.085,
      "step": 660
    },
    {
      "epoch": 0.06887470880178263,
      "grad_norm": 8.7505464553833,
      "learning_rate": 4.931327863871164e-05,
      "loss": 0.1089,
      "step": 680
    },
    {
      "epoch": 0.07090043553124684,
      "grad_norm": 2.4463045597076416,
      "learning_rate": 4.9293021371416996e-05,
      "loss": 0.0881,
      "step": 700
    },
    {
      "epoch": 0.07292616226071102,
      "grad_norm": 2.3883886337280273,
      "learning_rate": 4.9272764104122354e-05,
      "loss": 0.1098,
      "step": 720
    },
    {
      "epoch": 0.07495188899017523,
      "grad_norm": 1.602027177810669,
      "learning_rate": 4.925250683682772e-05,
      "loss": 0.1225,
      "step": 740
    },
    {
      "epoch": 0.07697761571963942,
      "grad_norm": 3.593160390853882,
      "learning_rate": 4.9232249569533075e-05,
      "loss": 0.1089,
      "step": 760
    },
    {
      "epoch": 0.07900334244910362,
      "grad_norm": 0.7113755345344543,
      "learning_rate": 4.921199230223843e-05,
      "loss": 0.0966,
      "step": 780
    },
    {
      "epoch": 0.08102906917856781,
      "grad_norm": 3.9807815551757812,
      "learning_rate": 4.919173503494379e-05,
      "loss": 0.1001,
      "step": 800
    },
    {
      "epoch": 0.08305479590803201,
      "grad_norm": 1.8223150968551636,
      "learning_rate": 4.917147776764915e-05,
      "loss": 0.1339,
      "step": 820
    },
    {
      "epoch": 0.0850805226374962,
      "grad_norm": 2.0231804847717285,
      "learning_rate": 4.9151220500354504e-05,
      "loss": 0.1171,
      "step": 840
    },
    {
      "epoch": 0.0871062493669604,
      "grad_norm": 2.085484027862549,
      "learning_rate": 4.913096323305986e-05,
      "loss": 0.1049,
      "step": 860
    },
    {
      "epoch": 0.08913197609642459,
      "grad_norm": 2.450080633163452,
      "learning_rate": 4.911070596576522e-05,
      "loss": 0.0904,
      "step": 880
    },
    {
      "epoch": 0.09115770282588878,
      "grad_norm": 3.7373743057250977,
      "learning_rate": 4.909044869847058e-05,
      "loss": 0.1062,
      "step": 900
    },
    {
      "epoch": 0.09318342955535298,
      "grad_norm": 0.4202941656112671,
      "learning_rate": 4.907019143117594e-05,
      "loss": 0.1187,
      "step": 920
    },
    {
      "epoch": 0.09520915628481717,
      "grad_norm": 1.1584241390228271,
      "learning_rate": 4.90499341638813e-05,
      "loss": 0.1048,
      "step": 940
    },
    {
      "epoch": 0.09723488301428138,
      "grad_norm": 5.440037250518799,
      "learning_rate": 4.902967689658665e-05,
      "loss": 0.1098,
      "step": 960
    },
    {
      "epoch": 0.09926060974374556,
      "grad_norm": 4.4612321853637695,
      "learning_rate": 4.9009419629292006e-05,
      "loss": 0.1114,
      "step": 980
    },
    {
      "epoch": 0.10128633647320977,
      "grad_norm": 0.742353618144989,
      "learning_rate": 4.898916236199737e-05,
      "loss": 0.0886,
      "step": 1000
    },
    {
      "epoch": 0.10331206320267396,
      "grad_norm": 1.4377676248550415,
      "learning_rate": 4.896890509470273e-05,
      "loss": 0.0793,
      "step": 1020
    },
    {
      "epoch": 0.10533778993213816,
      "grad_norm": 4.384881973266602,
      "learning_rate": 4.8948647827408084e-05,
      "loss": 0.0849,
      "step": 1040
    },
    {
      "epoch": 0.10736351666160235,
      "grad_norm": 4.020693778991699,
      "learning_rate": 4.892839056011344e-05,
      "loss": 0.0966,
      "step": 1060
    },
    {
      "epoch": 0.10938924339106655,
      "grad_norm": 3.715514659881592,
      "learning_rate": 4.8908133292818806e-05,
      "loss": 0.0908,
      "step": 1080
    },
    {
      "epoch": 0.11141497012053074,
      "grad_norm": 3.8350300788879395,
      "learning_rate": 4.8887876025524156e-05,
      "loss": 0.0788,
      "step": 1100
    },
    {
      "epoch": 0.11344069684999493,
      "grad_norm": 3.954622983932495,
      "learning_rate": 4.8867618758229514e-05,
      "loss": 0.1081,
      "step": 1120
    },
    {
      "epoch": 0.11546642357945913,
      "grad_norm": 2.855602264404297,
      "learning_rate": 4.884736149093487e-05,
      "loss": 0.0886,
      "step": 1140
    },
    {
      "epoch": 0.11749215030892332,
      "grad_norm": 1.824524998664856,
      "learning_rate": 4.8827104223640235e-05,
      "loss": 0.1221,
      "step": 1160
    },
    {
      "epoch": 0.11951787703838752,
      "grad_norm": 1.3839136362075806,
      "learning_rate": 4.880684695634559e-05,
      "loss": 0.0919,
      "step": 1180
    },
    {
      "epoch": 0.12154360376785171,
      "grad_norm": 0.7302467823028564,
      "learning_rate": 4.878658968905095e-05,
      "loss": 0.0912,
      "step": 1200
    },
    {
      "epoch": 0.12356933049731592,
      "grad_norm": 3.86795711517334,
      "learning_rate": 4.876633242175631e-05,
      "loss": 0.0926,
      "step": 1220
    },
    {
      "epoch": 0.1255950572267801,
      "grad_norm": 1.6369811296463013,
      "learning_rate": 4.8746075154461664e-05,
      "loss": 0.1145,
      "step": 1240
    },
    {
      "epoch": 0.1276207839562443,
      "grad_norm": 3.724612236022949,
      "learning_rate": 4.872581788716702e-05,
      "loss": 0.0853,
      "step": 1260
    },
    {
      "epoch": 0.1296465106857085,
      "grad_norm": 1.9994053840637207,
      "learning_rate": 4.870556061987238e-05,
      "loss": 0.1069,
      "step": 1280
    },
    {
      "epoch": 0.1316722374151727,
      "grad_norm": 3.5466084480285645,
      "learning_rate": 4.8685303352577736e-05,
      "loss": 0.0942,
      "step": 1300
    },
    {
      "epoch": 0.1336979641446369,
      "grad_norm": 2.0595154762268066,
      "learning_rate": 4.86650460852831e-05,
      "loss": 0.1033,
      "step": 1320
    },
    {
      "epoch": 0.13572369087410108,
      "grad_norm": 4.374864101409912,
      "learning_rate": 4.864478881798846e-05,
      "loss": 0.1002,
      "step": 1340
    },
    {
      "epoch": 0.13774941760356527,
      "grad_norm": 1.7625739574432373,
      "learning_rate": 4.8624531550693815e-05,
      "loss": 0.0841,
      "step": 1360
    },
    {
      "epoch": 0.13977514433302948,
      "grad_norm": 0.4529566764831543,
      "learning_rate": 4.860427428339917e-05,
      "loss": 0.0925,
      "step": 1380
    },
    {
      "epoch": 0.14180087106249367,
      "grad_norm": 0.9075517654418945,
      "learning_rate": 4.858401701610453e-05,
      "loss": 0.0806,
      "step": 1400
    },
    {
      "epoch": 0.14382659779195786,
      "grad_norm": 2.2661941051483154,
      "learning_rate": 4.856375974880989e-05,
      "loss": 0.0981,
      "step": 1420
    },
    {
      "epoch": 0.14585232452142205,
      "grad_norm": 1.4321025609970093,
      "learning_rate": 4.8543502481515245e-05,
      "loss": 0.0979,
      "step": 1440
    },
    {
      "epoch": 0.14787805125088627,
      "grad_norm": 1.6863058805465698,
      "learning_rate": 4.85232452142206e-05,
      "loss": 0.0853,
      "step": 1460
    },
    {
      "epoch": 0.14990377798035046,
      "grad_norm": 5.636297702789307,
      "learning_rate": 4.850298794692596e-05,
      "loss": 0.0824,
      "step": 1480
    },
    {
      "epoch": 0.15192950470981464,
      "grad_norm": 3.084430694580078,
      "learning_rate": 4.848273067963132e-05,
      "loss": 0.0846,
      "step": 1500
    },
    {
      "epoch": 0.15395523143927883,
      "grad_norm": 3.261409044265747,
      "learning_rate": 4.846247341233668e-05,
      "loss": 0.0691,
      "step": 1520
    },
    {
      "epoch": 0.15598095816874305,
      "grad_norm": 3.1074233055114746,
      "learning_rate": 4.844221614504204e-05,
      "loss": 0.0897,
      "step": 1540
    },
    {
      "epoch": 0.15800668489820724,
      "grad_norm": 0.5317603945732117,
      "learning_rate": 4.8421958877747395e-05,
      "loss": 0.093,
      "step": 1560
    },
    {
      "epoch": 0.16003241162767143,
      "grad_norm": 2.0394747257232666,
      "learning_rate": 4.840170161045275e-05,
      "loss": 0.0977,
      "step": 1580
    },
    {
      "epoch": 0.16205813835713562,
      "grad_norm": 3.39489483833313,
      "learning_rate": 4.838144434315811e-05,
      "loss": 0.0728,
      "step": 1600
    },
    {
      "epoch": 0.1640838650865998,
      "grad_norm": 1.8567018508911133,
      "learning_rate": 4.836118707586347e-05,
      "loss": 0.0927,
      "step": 1620
    },
    {
      "epoch": 0.16610959181606402,
      "grad_norm": 4.8946051597595215,
      "learning_rate": 4.8340929808568825e-05,
      "loss": 0.0846,
      "step": 1640
    },
    {
      "epoch": 0.1681353185455282,
      "grad_norm": 1.7306632995605469,
      "learning_rate": 4.832067254127419e-05,
      "loss": 0.0833,
      "step": 1660
    },
    {
      "epoch": 0.1701610452749924,
      "grad_norm": 3.3726768493652344,
      "learning_rate": 4.8300415273979546e-05,
      "loss": 0.078,
      "step": 1680
    },
    {
      "epoch": 0.1721867720044566,
      "grad_norm": 2.359534502029419,
      "learning_rate": 4.82801580066849e-05,
      "loss": 0.0878,
      "step": 1700
    },
    {
      "epoch": 0.1742124987339208,
      "grad_norm": 3.4029746055603027,
      "learning_rate": 4.8259900739390254e-05,
      "loss": 0.0727,
      "step": 1720
    },
    {
      "epoch": 0.176238225463385,
      "grad_norm": 2.545952081680298,
      "learning_rate": 4.823964347209562e-05,
      "loss": 0.097,
      "step": 1740
    },
    {
      "epoch": 0.17826395219284918,
      "grad_norm": 0.601554811000824,
      "learning_rate": 4.8219386204800975e-05,
      "loss": 0.0767,
      "step": 1760
    },
    {
      "epoch": 0.18028967892231337,
      "grad_norm": 2.0860595703125,
      "learning_rate": 4.819912893750633e-05,
      "loss": 0.082,
      "step": 1780
    },
    {
      "epoch": 0.18231540565177756,
      "grad_norm": 1.0707210302352905,
      "learning_rate": 4.817887167021169e-05,
      "loss": 0.0809,
      "step": 1800
    },
    {
      "epoch": 0.18434113238124178,
      "grad_norm": 1.3055371046066284,
      "learning_rate": 4.815861440291705e-05,
      "loss": 0.0826,
      "step": 1820
    },
    {
      "epoch": 0.18636685911070597,
      "grad_norm": 5.095804691314697,
      "learning_rate": 4.813835713562241e-05,
      "loss": 0.0975,
      "step": 1840
    },
    {
      "epoch": 0.18839258584017016,
      "grad_norm": 5.071376800537109,
      "learning_rate": 4.811809986832776e-05,
      "loss": 0.0819,
      "step": 1860
    },
    {
      "epoch": 0.19041831256963435,
      "grad_norm": 0.8535410165786743,
      "learning_rate": 4.809784260103312e-05,
      "loss": 0.1152,
      "step": 1880
    },
    {
      "epoch": 0.19244403929909856,
      "grad_norm": 5.563859939575195,
      "learning_rate": 4.807758533373848e-05,
      "loss": 0.0911,
      "step": 1900
    },
    {
      "epoch": 0.19446976602856275,
      "grad_norm": 3.1616997718811035,
      "learning_rate": 4.805732806644384e-05,
      "loss": 0.0687,
      "step": 1920
    },
    {
      "epoch": 0.19649549275802694,
      "grad_norm": 2.801802635192871,
      "learning_rate": 4.80370707991492e-05,
      "loss": 0.113,
      "step": 1940
    },
    {
      "epoch": 0.19852121948749113,
      "grad_norm": 2.129056453704834,
      "learning_rate": 4.8016813531854555e-05,
      "loss": 0.0709,
      "step": 1960
    },
    {
      "epoch": 0.20054694621695535,
      "grad_norm": 0.7857062816619873,
      "learning_rate": 4.799655626455991e-05,
      "loss": 0.0828,
      "step": 1980
    },
    {
      "epoch": 0.20257267294641954,
      "grad_norm": 1.934816837310791,
      "learning_rate": 4.797629899726527e-05,
      "loss": 0.0894,
      "step": 2000
    },
    {
      "epoch": 0.20459839967588372,
      "grad_norm": 1.025107979774475,
      "learning_rate": 4.795604172997063e-05,
      "loss": 0.0902,
      "step": 2020
    },
    {
      "epoch": 0.2066241264053479,
      "grad_norm": 6.731165409088135,
      "learning_rate": 4.7935784462675985e-05,
      "loss": 0.0722,
      "step": 2040
    },
    {
      "epoch": 0.2086498531348121,
      "grad_norm": 1.011865258216858,
      "learning_rate": 4.791552719538134e-05,
      "loss": 0.1106,
      "step": 2060
    },
    {
      "epoch": 0.21067557986427632,
      "grad_norm": 1.3838727474212646,
      "learning_rate": 4.7895269928086706e-05,
      "loss": 0.0831,
      "step": 2080
    },
    {
      "epoch": 0.2127013065937405,
      "grad_norm": 0.6243904232978821,
      "learning_rate": 4.7875012660792064e-05,
      "loss": 0.0732,
      "step": 2100
    },
    {
      "epoch": 0.2147270333232047,
      "grad_norm": 3.1797947883605957,
      "learning_rate": 4.785475539349742e-05,
      "loss": 0.0771,
      "step": 2120
    },
    {
      "epoch": 0.21675276005266889,
      "grad_norm": 2.2815277576446533,
      "learning_rate": 4.783449812620278e-05,
      "loss": 0.0678,
      "step": 2140
    },
    {
      "epoch": 0.2187784867821331,
      "grad_norm": 3.956819534301758,
      "learning_rate": 4.7814240858908136e-05,
      "loss": 0.0931,
      "step": 2160
    },
    {
      "epoch": 0.2208042135115973,
      "grad_norm": 1.396185040473938,
      "learning_rate": 4.779398359161349e-05,
      "loss": 0.0625,
      "step": 2180
    },
    {
      "epoch": 0.22282994024106148,
      "grad_norm": 1.3436113595962524,
      "learning_rate": 4.777372632431885e-05,
      "loss": 0.0787,
      "step": 2200
    },
    {
      "epoch": 0.22485566697052567,
      "grad_norm": 0.8193346261978149,
      "learning_rate": 4.775346905702421e-05,
      "loss": 0.0799,
      "step": 2220
    },
    {
      "epoch": 0.22688139369998986,
      "grad_norm": 1.4557431936264038,
      "learning_rate": 4.77342246530943e-05,
      "loss": 0.0831,
      "step": 2240
    },
    {
      "epoch": 0.22890712042945408,
      "grad_norm": 3.8163321018218994,
      "learning_rate": 4.7713967385799656e-05,
      "loss": 0.082,
      "step": 2260
    },
    {
      "epoch": 0.23093284715891826,
      "grad_norm": 1.1078115701675415,
      "learning_rate": 4.769371011850501e-05,
      "loss": 0.078,
      "step": 2280
    },
    {
      "epoch": 0.23295857388838245,
      "grad_norm": 0.7755193710327148,
      "learning_rate": 4.767345285121038e-05,
      "loss": 0.0859,
      "step": 2300
    },
    {
      "epoch": 0.23498430061784664,
      "grad_norm": 0.732910692691803,
      "learning_rate": 4.7653195583915734e-05,
      "loss": 0.0816,
      "step": 2320
    },
    {
      "epoch": 0.23701002734731086,
      "grad_norm": 0.26668816804885864,
      "learning_rate": 4.763293831662109e-05,
      "loss": 0.0962,
      "step": 2340
    },
    {
      "epoch": 0.23903575407677505,
      "grad_norm": 1.6725592613220215,
      "learning_rate": 4.761268104932645e-05,
      "loss": 0.0674,
      "step": 2360
    },
    {
      "epoch": 0.24106148080623924,
      "grad_norm": 6.149289131164551,
      "learning_rate": 4.7592423782031806e-05,
      "loss": 0.0894,
      "step": 2380
    },
    {
      "epoch": 0.24308720753570343,
      "grad_norm": 0.8772679567337036,
      "learning_rate": 4.7572166514737164e-05,
      "loss": 0.088,
      "step": 2400
    },
    {
      "epoch": 0.24511293426516764,
      "grad_norm": 1.2106103897094727,
      "learning_rate": 4.755190924744252e-05,
      "loss": 0.0619,
      "step": 2420
    },
    {
      "epoch": 0.24713866099463183,
      "grad_norm": 0.3283914029598236,
      "learning_rate": 4.753165198014788e-05,
      "loss": 0.0742,
      "step": 2440
    },
    {
      "epoch": 0.24916438772409602,
      "grad_norm": 1.6110930442810059,
      "learning_rate": 4.751139471285324e-05,
      "loss": 0.0734,
      "step": 2460
    },
    {
      "epoch": 0.2511901144535602,
      "grad_norm": 19.203628540039062,
      "learning_rate": 4.74911374455586e-05,
      "loss": 0.094,
      "step": 2480
    },
    {
      "epoch": 0.2532158411830244,
      "grad_norm": 2.5331056118011475,
      "learning_rate": 4.747088017826396e-05,
      "loss": 0.0979,
      "step": 2500
    }
  ],
  "logging_steps": 20,
  "max_steps": 49365,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.7527955521536e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
